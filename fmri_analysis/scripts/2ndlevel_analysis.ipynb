{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from functools import partial\n",
    "from glob import glob\n",
    "from joblib import Parallel, delayed\n",
    "import json\n",
    "import nibabel\n",
    "from nilearn import image\n",
    "import numpy as np\n",
    "from os import makedirs, path, sep\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.spatial.distance import squareform\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "from utils.secondlevel_utils import *\n",
    "from utils.secondlevel_plot_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnecessary imports, for exploring\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Arguments\n",
    "These are not needed for the jupyter notebook, but are used after conversion to a script for production\n",
    "\n",
    "- conversion command:\n",
    "  - jupyter nbconvert --to script --execute 2ndlevel_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='fMRI Analysis Entrypoint Script.')\n",
    "parser.add_argument('-derivatives_dir')\n",
    "parser.add_argument('-working_dir', default=None)\n",
    "parser.add_argument('--tasks', nargs=\"+\")\n",
    "parser.add_argument('--n_procs', default=4, type=int)\n",
    "parser.add_argument('--num_perm', default=1000, type=int, help=\"Passed to fsl.randomize\")\n",
    "parser.add_argument('--ignore_rt', action='store_false')\n",
    "parser.add_argument('--rerun', action='store_true')\n",
    "parser.add_argument('--mask_threshold', default=.8, type=float)\n",
    "if '-derivatives_dir' in sys.argv or '-h' in sys.argv:\n",
    "    args = parser.parse_args()\n",
    "    num_files = None\n",
    "else:\n",
    "    # if run as a notebook reduce the number of files used and set of args\n",
    "    args = parser.parse_args([])\n",
    "    args.derivatives_dir='/data/derivatives'\n",
    "    num_files = None\n",
    "    args.rerun = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives_dir = args.derivatives_dir\n",
    "fmriprep_dir = path.join(derivatives_dir, 'fmriprep', 'fmriprep')\n",
    "first_level_dir = path.join(derivatives_dir, '1stlevel')\n",
    "second_level_dir = path.join(derivatives_dir,'2ndlevel')\n",
    "if args.working_dir is None:\n",
    "    working_dir = path.join(derivatives_dir, '2ndlevel_workingdir')\n",
    "else:\n",
    "    working_dir = path.join(args.working_dir, '2ndlevel_workingdir')\n",
    "makedirs(working_dir, exist_ok=True)\n",
    "    \n",
    "tasks = ['ANT', 'CCTHot', 'discountFix',\n",
    "         'DPX', 'motorSelectiveStop',\n",
    "         'stopSignal', 'stroop', \n",
    "         'surveyMedley', 'twoByTwo', 'WATT3']\n",
    "if args.tasks:\n",
    "    tasks = args.tasks\n",
    "regress_rt = args.ignore_rt\n",
    "model = 'model-rt' if regress_rt == True else 'model-nort'\n",
    "mask_threshold = args.mask_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Group Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask over all tasks\n",
    "# create 95% brain mask\n",
    "mask_loc = path.join(second_level_dir, 'group_mask_thresh-%s.nii.gz' % str(mask_threshold))\n",
    "if path.exists(mask_loc) == False:\n",
    "    create_group_mask(mask_loc, fmriprep_dir, mask_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_img(mask_loc, title='Group Mask, Threshold: %s%%' % str(mask_threshold*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up functions with some default parameters\n",
    "get_group_maps = partial(get_group_maps, second_level_dir=second_level_dir,\n",
    "                        tasks=tasks, model=model)\n",
    "get_ICA_parcellation = partial(get_ICA_parcellation, second_level_dir=second_level_dir,\n",
    "                               mask_loc=mask_loc, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data files\n",
    "file_type = 'zstat'\n",
    "map_files = get_map_files(map_prefix=file_type, \n",
    "                          first_level_dir=first_level_dir,\n",
    "                        tasks=tasks, model=model)\n",
    "contrast_names = list(map_files.keys())\n",
    "# reduce the number of files to make execution quicker for testing\n",
    "def random_sample(lst, n):\n",
    "    return [lst[i] for i in np.random.choice(range(len(lst)), n, replace=False)]\n",
    "if num_files is not None:\n",
    "    map_files = {k:random_sample(v, num_files) for k,v in map_files.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#iterative version\n",
    "concat_out = concat_map_files(map_files, file_type=individual_file_type,\n",
    "                                second_level_dir=second_level_dir, model=model,\n",
    "                                verbose=True)\n",
    "\"\"\"\n",
    "# concat files in parallel\n",
    "concat_map_files = partial(concat_map_files, file_type=file_type,\n",
    "                           second_level_dir=second_level_dir, model=model, verbose=False,\n",
    "                          rerun=args.rerun)\n",
    "\n",
    "list_dicts = [{k:map_files[k]} for k in map_files.keys()]\n",
    "concat_out = Parallel(n_jobs=args.n_procs)(delayed(concat_map_files)(task) for task in list_dicts)\n",
    "concat_out = flatten(concat_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #iterative version\n",
    "# smooth_out = smooth_concat_files(concated_map_files, verbose=True)\n",
    "# smooth files in parallel\n",
    "smooth_concat_files = partial(smooth_concat_files, verbose=False, rerun=args.rerun)\n",
    "smooth_out = Parallel(n_jobs=args.n_procs)(delayed(smooth_concat_files)([concat_file]) for concat_file in concat_out)\n",
    "smooth_out = flatten(smooth_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Group Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then tmap\n",
    "contrast_tmap_parallel = partial(save_tmaps, mask_loc=mask_loc, working_dir=working_dir, \n",
    "                                 permutations=args.num_perm, rerun=args.rerun)\n",
    "tmap_out = Parallel(n_jobs=args.n_procs)(delayed(contrast_tmap_parallel)(filey) for filey in smooth_out)\n",
    "tmap_raw, tmap_correct = zip(*tmap_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# % matplotlib inline\n",
    "# task_contrast_dirs = sorted(glob(path.join(second_level_dir, '*', 'model-rt', 'wf-contrast')))\n",
    "# for d in task_contrast_dirs:\n",
    "#     plot_2ndlevel_maps(d, lookup='*corrected*', threshold=.95) # *raw* for raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parcellations, Atlases and RDM\n",
    "\n",
    "Projecting into a lower dimensional space allows the evaluation of whole-brain similarity analysis (clustering)\n",
    "\n",
    "RDMs can also be evaluated within parcellation regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get parcellations to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcellation_dir = path.join(second_level_dir, 'parcellation')\n",
    "\"\"\"\n",
    "# calculate ICA parcel\n",
    "n_comps = 20; ICA_prefix = 'contrast'\n",
    "ICA_path = path.join(parcellation_dir, '%s_canica%s.nii.gz' % (ICA_prefix, n_comps))\n",
    "if path.exists(ICA_path) and not args.rerun:\n",
    "    ICA_parcel = image.load_img(path.join(parcellation_dir, '%s_canica%s.nii.gz' % (ICA_prefix, n_comps)))\n",
    "else:\n",
    "    ICA_parcel = get_ICA_parcellation(map_files, n_comps=n_comps, file_name=ICA_prefix)\n",
    "\"\"\"\n",
    "# get literature parcels\n",
    "target_img = list(map_files.values())[0] # get image to resample atlases to\n",
    "harvard = get_established_parcellation(\"Harvard_Oxford\", target_img=target_img, download_dir=parcellation_dir)\n",
    "smith = get_established_parcellation(\"smith\", target_img=target_img, download_dir=parcellation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plotting.plot_prob_atlas(harvard_parcel)\n",
    "# # what is RegionExtractor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use parcellation to create ROIs and calculate RDMs amongst contrasts within each ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel, parcel_labels, parcel_name, threshold = harvard\n",
    "roi_extraction_dir = second_level_dir\n",
    "atlas = parcel_to_atlas(parcel, threshold)\n",
    "to_extract = concat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_prob_atlas(parcel, title=\"Parcellation\", cut_coords=[0, -41, 10])\n",
    "plotting.plot_roi(atlas, title=\"Atlas Version\", cut_coords=[0, -41, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RDMs for each region for each group map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average smoothed map for each contrast\n",
    "group_map_files = get_mean_maps(to_extract, contrast_names, save=True, rerun=args.rerun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_extraction_file = path.join(second_level_dir, 'Extracted_Data', \n",
    "                            'parcel-%s' % parcel_name,\n",
    "                            'groupcontrasts_extraction.pkl')\n",
    "if path.exists(group_extraction_file) and not args.rerun:\n",
    "    group_roi_contrasts = pickle.load(open(group_extraction_file, 'rb'))\n",
    "else:\n",
    "    group_roi_contrasts = extract_roi_vals(list(group_map_files.values()), parcel, threshold, \n",
    "                                           labels=parcel_labels, metadata=get_metadata(group_map_files),\n",
    "                                           n_procs=args.n_procs) \n",
    "    pickle.dump(group_roi_contrasts, open(group_extraction_file, 'wb'))\n",
    "group_RDMs = get_RDMs(group_roi_contrasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot random RDM\n",
    "label = np.random.choice(list(group_RDMs.keys()))\n",
    "index = parcel_labels.index(label)\n",
    "roi = get_ROI_from_parcel(parcel, index, threshold)\n",
    "RDM = pd.DataFrame(group_RDMs[label], index=group_map_files.keys())\n",
    "plot_RDM(RDM, roi, title=label, cluster=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDM of RDMs\n",
    "\n",
    "Each ROI has an RDM reflecting its \"representation\" of cognitive faculties probed by these contrasts. We can look at the similarity of RDMs to get a sense of the similarity of the cognitive fingerprint of individual regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tril(square_mat):\n",
    "    return square_mat[np.tril_indices_from(square_mat, -1)]\n",
    "\n",
    "# similarity of RDMs\n",
    "keys = list(group_RDMs.keys())\n",
    "vectorized_RDMs = np.vstack([tril(group_RDMs[k]) for k in keys])\n",
    "vectorized_RDMs = pd.DataFrame(vectorized_RDMs, index=keys)\n",
    "RDM_of_RDMs = 1-vectorized_RDMs.T.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize RDM of RDMs\n",
    "sns.clustermap(RDM_of_RDMs, figsize=[15,15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA of RDMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from scipy.spatial.distance import squareform\n",
    "from itertools import combinations\n",
    "pca = PCA(3)\n",
    "pca_RDMs = pca.fit_transform(vectorized_RDMs)\n",
    "scaled = minmax_scale(pca_RDMs)\n",
    "\n",
    "# we can then color the first 3 PCA components (RGB) and create color mixtures reflecting the RDM signature\n",
    "colors = np.array([[1,0,0], [0,1,0], [0,0,1]])\n",
    "def combined_colors(array, colors=colors):\n",
    "    return np.dot(colors, array)\n",
    "colored_pca = np.apply_along_axis(combined_colors, 1, scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare RDM after dimensional reduction\n",
    "i = np.random.randint(vectorized_RDMs.shape[0])\n",
    "f, axes = plt.subplots(1,2,figsize=(12,5))\n",
    "orig = vectorized_RDMs.iloc[i,:]\n",
    "reconstruction = pca.inverse_transform(pca_RDMs[i,:])\n",
    "corr = np.corrcoef(orig, reconstruction)[0,1]\n",
    "sns.heatmap(squareform(orig), ax=axes[0])\n",
    "sns.heatmap(squareform(reconstruction), ax=axes[1])\n",
    "axes[0].set_title(vectorized_RDMs.index[i])\n",
    "axes[1].set_title('PCA (%s) reconstruction, Corr: %0.2f' % (str(pca.n_components), corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "cm = ListedColormap(colored_pca)\n",
    "f=plt.figure(figsize=(12,8))\n",
    "plotting.plot_prob_atlas(parcel, cmap=cm, view_type='filled_contours', figure=f, \n",
    "                         title=\"RDM -> PCA -> colors (1: Red, 2: Green, 3: Blue)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also visualize the RDMs reflecting each of these first 3 components\n",
    "n_cols = 3\n",
    "n_rows = pca.n_components//n_cols\n",
    "f, axes = plt.subplots(n_rows, n_cols,\n",
    "                      figsize = (5*n_cols, 5*n_rows))\n",
    "axes = f.get_axes()\n",
    "for i, component in enumerate(pca.components_):\n",
    "    sns.heatmap(squareform(component), ax=axes[i])\n",
    "    axes[i].set_title('PCA Components %s' % str(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RDMs for each region for each subject-contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_dir = path.join(second_level_dir, 'Extracted_Data', \n",
    "                            'parcel-%s' % parcel_name)\n",
    "makedirs(path.dirname(extraction_dir), exist_ok=True)\n",
    "metadata = get_metadata(to_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "%%time\n",
    "files = extract_roi_vals(to_extract, parcel, extraction_dir, \n",
    "                 threshold=threshold, metadata=metadata, \n",
    "                 labels=parcel_labels, rerun=args.rerun, \n",
    "                 n_procs=1, rois=[1])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "labels = parcel_labels\n",
    "rerun=True\n",
    "rois = [0, 1, 2, 3, 4]\n",
    "files = []\n",
    "for roi_i in rois:\n",
    "    \n",
    "    if labels is not None:\n",
    "        key = labels[roi_i]\n",
    "    else:\n",
    "        key = roi_i\n",
    "    file = path.join(extraction_dir, 'contrasts_ROI-%s_extraction.pkl' % key)\n",
    "    if not path.exists(file) or rerun:\n",
    "        print(\"Masking %s\" % key)\n",
    "        mask_img = get_ROI_from_parcel(parcel, roi_i, threshold)\n",
    "        masked_map = masking.apply_mask(to_extract, mask_img=mask_img)\n",
    "        if metadata is not None:\n",
    "            masked_map = pd.concat([metadata, pd.DataFrame(masked_map)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDMs = get_RDMs(roi_contrasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot random RDM\n",
    "label = np.random.choice(list(RDMs.keys()))\n",
    "index = parcel_labels.index(label)\n",
    "roi = get_ROI_from_parcel(parcel, index, threshold)\n",
    "plot_RDM(RDMs[label], roi, title=label, cluster=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSA Searchlight\n",
    "http://www.pymvpa.org/examples/rsa_fmri.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply parcellations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ********************************************************\n",
    "# Set up parcellation\n",
    "# ********************************************************\n",
    "\n",
    "#******************* Estimate parcellation from data ***********************\n",
    "print('Creating ICA based parcellation')\n",
    "\n",
    "\n",
    "# group map files by subject\n",
    "subject_ids = np.unique([f.split(os.sep)[-2].split('_')[0] for f in map_files])\n",
    "subject_map_files = []\n",
    "for s in subject_ids:\n",
    "    subject_map_files.append(image.concat_imgs([f for f in map_files if s in f]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ********************************************************\n",
    "# Reduce dimensionality of contrasts\n",
    "# ********************************************************\n",
    "def split_index(projections_df):\n",
    "    subj = [f.split('_')[0] for f in projections_df.index]\n",
    "    contrast = ['_'.join(f.split('_')[1:]) for f in projections_df.index]\n",
    "    projections_df.insert(0, 'subj', subj)\n",
    "    projections_df.insert(1, 'contrast', contrast)\n",
    "    \n",
    "    \n",
    "parcellation_files = [('smith70', smith_networks),\n",
    "                      ('canica20', \n",
    "                       join(output_dir, 'canica20_explicit_contrasts.nii.gz')),\n",
    "                      ('canica50', \n",
    "                       join(output_dir, 'canica50_explicit_contrasts.nii.gz')),\n",
    "                       ('canica70', \n",
    "                       join(output_dir, 'canica70_explicit_contrasts.nii.gz'))\n",
    "                       ]\n",
    "\n",
    "for parcellation_name, parcellation_file in parcellation_files:\n",
    "    projection_filey = join(output_dir, '%s_projection.json' % parcellation_name)\n",
    "    mask_file = join(output_dir, 'group_mask.nii.gz')\n",
    "    projections_df = create_projections_df(parcellation_file, mask_file, \n",
    "                                           data_dir, tasks, projection_filey)\n",
    "    \n",
    "    # create a subject x neural feature vector where each column is a component\n",
    "    # for one contrast\n",
    "    neural_feature_mat = create_neural_feature_mat(projections_df,\n",
    "                                                   filename=join(output_dir, \n",
    "                                                        '%s_neural_features.json'  \n",
    "                                                        % parcellation_name))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
