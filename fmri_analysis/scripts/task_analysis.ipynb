{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from glob import glob\n",
    "from nipype.interfaces import afni\n",
    "from nipype.interfaces import fsl\n",
    "from nipype.algorithms.modelgen import SpecifyModel\n",
    "from nipype.interfaces.utility import Function, IdentityInterface\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.pipeline.engine import Workflow, Node\n",
    "from os import makedirs\n",
    "from os.path import abspath, join\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from utils.utils import move_EVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/mnt/OAK'\n",
    "experiment_dir = '/home/ian/temp'\n",
    "output_dir = '1stLevel'\n",
    "working_dir = 'workingdir'\n",
    "\n",
    "# list of subject identifiers\n",
    "subject_list = ['sub-s358']\n",
    "\n",
    "# list of task identifiers\n",
    "task_list = ['surveyMedley', 'ANT', 'CCTHot', 'DPX', 'twoByTwo']\n",
    "\n",
    "# TR of functional images\n",
    "TR = .68\n",
    "\n",
    "regress_rt=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move_EV failed for the sub-s061: ANT\n",
      "Move_EV failed for the sub-s144: surveyMedley\n",
      "Move_EV failed for the sub-s144: DPX\n",
      "Move_EV failed for the sub-s491: CCTHot\n",
      "Move_EV failed for the sub-s513: surveyMedley\n",
      "Move_EV failed for the sub-s513: DPX\n",
      "Move_EV failed for the sub-s518: surveyMedley\n",
      "Move_EV failed for the sub-s518: ANT\n",
      "Move_EV failed for the sub-s518: CCTHot\n",
      "Move_EV failed for the sub-s518: twoByTwo\n",
      "Move_EV failed for the sub-s592: ANT\n",
      "Move_EV failed for the sub-s592: CCTHot\n",
      "Move_EV failed for the sub-s592: twoByTwo\n",
      "Move_EV failed for the sub-s603: surveyMedley\n",
      "Move_EV failed for the sub-s603: DPX\n",
      "Move_EV failed for the sub-s607: ANT\n",
      "Move_EV failed for the sub-s608: surveyMedley\n",
      "Move_EV failed for the sub-s608: twoByTwo\n",
      "Move_EV failed for the sub-s609: ANT\n",
      "Move_EV failed for the sub-s618: surveyMedley\n",
      "Move_EV failed for the sub-s623: ANT\n",
      "Move_EV failed for the sub-s623: CCTHot\n",
      "Move_EV failed for the sub-s623: twoByTwo\n",
      "Move_EV failed for the sub-s625: ANT\n",
      "Move_EV failed for the sub-s625: CCTHot\n",
      "Move_EV failed for the sub-s625: twoByTwo\n",
      "Move_EV failed for the sub-s628: surveyMedley\n",
      "Move_EV failed for the sub-s628: ANT\n",
      "Move_EV failed for the sub-s628: CCTHot\n",
      "Move_EV failed for the sub-s628: DPX\n",
      "Move_EV failed for the sub-s628: twoByTwo\n",
      "Move_EV failed for the sub-s629: surveyMedley\n",
      "Move_EV failed for the sub-s629: ANT\n",
      "Move_EV failed for the sub-s629: CCTHot\n",
      "Move_EV failed for the sub-s629: DPX\n",
      "Move_EV failed for the sub-s629: twoByTwo\n",
      "Move_EV failed for the sub-s631: surveyMedley\n",
      "Move_EV failed for the sub-s631: ANT\n",
      "Move_EV failed for the sub-s631: CCTHot\n",
      "Move_EV failed for the sub-s631: DPX\n",
      "Move_EV failed for the sub-s631: twoByTwo\n",
      "Move_EV failed for the sub-s633: surveyMedley\n",
      "Move_EV failed for the sub-s633: ANT\n",
      "Move_EV failed for the sub-s633: CCTHot\n",
      "Move_EV failed for the sub-s633: DPX\n",
      "Move_EV failed for the sub-s633: twoByTwo\n",
      "Move_EV failed for the sub-s634: surveyMedley\n",
      "Move_EV failed for the sub-s634: ANT\n",
      "Move_EV failed for the sub-s634: CCTHot\n",
      "Move_EV failed for the sub-s634: DPX\n",
      "Move_EV failed for the sub-s634: twoByTwo\n",
      "Move_EV failed for the sub-s635: surveyMedley\n",
      "Move_EV failed for the sub-s635: ANT\n",
      "Move_EV failed for the sub-s635: CCTHot\n",
      "Move_EV failed for the sub-s635: DPX\n",
      "Move_EV failed for the sub-s635: twoByTwo\n",
      "Move_EV failed for the sub-s636: surveyMedley\n",
      "Move_EV failed for the sub-s636: ANT\n",
      "Move_EV failed for the sub-s636: CCTHot\n",
      "Move_EV failed for the sub-s636: DPX\n",
      "Move_EV failed for the sub-s636: twoByTwo\n",
      "Move_EV failed for the sub-s637: surveyMedley\n",
      "Move_EV failed for the sub-s637: ANT\n",
      "Move_EV failed for the sub-s637: CCTHot\n",
      "Move_EV failed for the sub-s637: DPX\n",
      "Move_EV failed for the sub-s637: twoByTwo\n",
      "Move_EV failed for the sub-s638: surveyMedley\n",
      "Move_EV failed for the sub-s638: ANT\n",
      "Move_EV failed for the sub-s638: CCTHot\n",
      "Move_EV failed for the sub-s638: DPX\n",
      "Move_EV failed for the sub-s638: twoByTwo\n",
      "Move_EV failed for the sub-s640: surveyMedley\n",
      "Move_EV failed for the sub-s640: ANT\n",
      "Move_EV failed for the sub-s640: CCTHot\n",
      "Move_EV failed for the sub-s640: DPX\n",
      "Move_EV failed for the sub-s640: twoByTwo\n",
      "Move_EV failed for the sub-s641: surveyMedley\n",
      "Move_EV failed for the sub-s641: ANT\n",
      "Move_EV failed for the sub-s641: CCTHot\n",
      "Move_EV failed for the sub-s641: DPX\n",
      "Move_EV failed for the sub-s641: twoByTwo\n",
      "Move_EV failed for the sub-s642: surveyMedley\n",
      "Move_EV failed for the sub-s642: ANT\n",
      "Move_EV failed for the sub-s642: CCTHot\n",
      "Move_EV failed for the sub-s642: DPX\n",
      "Move_EV failed for the sub-s642: twoByTwo\n",
      "Move_EV failed for the sub-s643: surveyMedley\n",
      "Move_EV failed for the sub-s643: ANT\n",
      "Move_EV failed for the sub-s643: CCTHot\n",
      "Move_EV failed for the sub-s643: DPX\n",
      "Move_EV failed for the sub-s643: twoByTwo\n",
      "Move_EV failed for the sub-s644: surveyMedley\n",
      "Move_EV failed for the sub-s644: ANT\n",
      "Move_EV failed for the sub-s644: CCTHot\n",
      "Move_EV failed for the sub-s644: DPX\n",
      "Move_EV failed for the sub-s644: twoByTwo\n",
      "Move_EV failed for the sub-s645: surveyMedley\n",
      "Move_EV failed for the sub-s645: ANT\n",
      "Move_EV failed for the sub-s645: CCTHot\n",
      "Move_EV failed for the sub-s645: DPX\n",
      "Move_EV failed for the sub-s645: twoByTwo\n"
     ]
    }
   ],
   "source": [
    "events_dir = '/home/ian/Experiments/expfactory/Self_Regulation_Ontology_fMRI/Data/event_files/'\n",
    "if events_dir is not None:\n",
    "    move_EVs(events_dir, data_dir, task_list, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# helper function to create bunch\n",
    "def subjectinfo(data_dir, subject_id, task, \n",
    "                regress_rt, inspect_inputs=False):\n",
    "    \n",
    "    from glob import glob\n",
    "    from os.path import join\n",
    "    import pandas as pd\n",
    "    from nipype.interfaces.base import Bunch\n",
    "    from utils.utils import get_contrasts, parse_EVs, process_confounds\n",
    "    \n",
    "    # strip \"sub\" from beginning of subject_id if provided\n",
    "    subject_id = subject_id.replace('sub-','')\n",
    "    \n",
    "    ## Get the Events File\n",
    "    \n",
    "    # Read the TSV file and convert to pandas dataframe\n",
    "    event_file = glob(join(data_dir,\n",
    "                           'sub-%s' % subject_id,\n",
    "                           '*', 'func',\n",
    "                           '*%s*events.tsv' % task))[0]\n",
    "    events_df = pd.read_csv(event_file,sep = '\\t')\n",
    "\n",
    "    ## Get the Confounds File (output of fmriprep)\n",
    "    # Read the TSV file and convert to pandas dataframe\n",
    "    confounds_file = glob(join(data_dir,\n",
    "                               'sub-%s' % subject_id,\n",
    "                               '*', 'func',\n",
    "                               '*%s*confounds.tsv' % task))[0]\n",
    "    regressors, regressor_names = process_confounds(confounds_file)\n",
    "    \n",
    "    # set up contrasts\n",
    "    EV_dict = parse_EVs(events_df, task, regress_rt)\n",
    "    \n",
    "    subjectinfo = Bunch(conditions=EV_dict['conditions'],\n",
    "                        onsets=EV_dict['onsets'],\n",
    "                         durations=EV_dict['durations'],\n",
    "                         amplitudes=EV_dict['amplitudes'],\n",
    "                         tmod=None,\n",
    "                         pmod=None,\n",
    "                         regressor_names=regressor_names,\n",
    "                         regressors=regressors.T.tolist())\n",
    "    if inspect_inputs==True:\n",
    "        regressors_df = pd.DataFrame(regressors, columns = regressor_names)\n",
    "        return events_df, regressors_df\n",
    "    else:\n",
    "        contrasts = get_contrasts(task, regress_rt)\n",
    "        return subjectinfo, contrasts  # this output will later be returned to infosource\n",
    "\n",
    "def save_subjectinfo(base_directory, subject_id, task, subject_info, contrasts):\n",
    "    from os import makedirs\n",
    "    from os.path import join\n",
    "    import pickle\n",
    "    task_dir = join(base_directory, subject_id + '_task_' + task)\n",
    "    makedirs(task_dir, exist_ok=True)\n",
    "    subjectinfo_path = join(task_dir,'subjectinfo.pkl')\n",
    "    pickle.dump(subject_info, open(subjectinfo_path,'wb'))\n",
    "    \n",
    "    contrast_path = join(task_dir,'contrasts.pkl')\n",
    "    pickle.dump(contrasts, open(contrast_path,'wb'))\n",
    "    return (subjectinfo_path, contrast_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View one events file used in subject info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movement_onset</th>\n",
       "      <th>onset</th>\n",
       "      <th>response_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>coded_response</th>\n",
       "      <th>experiment_exp_id</th>\n",
       "      <th>item_coding</th>\n",
       "      <th>item_text</th>\n",
       "      <th>possible_responses</th>\n",
       "      <th>stim_duration</th>\n",
       "      <th>survey</th>\n",
       "      <th>text</th>\n",
       "      <th>time_elapsed</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>junk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>350.213</td>\n",
       "      <td>348.452</td>\n",
       "      <td>-1.7853</td>\n",
       "      <td>3.932</td>\n",
       "      <td>4.0</td>\n",
       "      <td>survey_medley</td>\n",
       "      <td>reverse</td>\n",
       "      <td>I am lazy.</td>\n",
       "      <td>66,89,71,82,77</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>brief</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357724</td>\n",
       "      <td>s358</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>362.048</td>\n",
       "      <td>357.727</td>\n",
       "      <td>0.7747</td>\n",
       "      <td>3.932</td>\n",
       "      <td>2.0</td>\n",
       "      <td>survey_medley</td>\n",
       "      <td>forward</td>\n",
       "      <td>Do you welcome new and exciting experiences an...</td>\n",
       "      <td>66,89</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>impulsive_venture</td>\n",
       "      <td>NaN</td>\n",
       "      <td>367339</td>\n",
       "      <td>s358</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>367.339</td>\n",
       "      <td>367.340</td>\n",
       "      <td>-3.5473</td>\n",
       "      <td>3.932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>survey_medley</td>\n",
       "      <td>forward</td>\n",
       "      <td>There is plenty of time left in my life to mak...</td>\n",
       "      <td>66,89,71,82,77</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>future_time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>376408</td>\n",
       "      <td>s358</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>382.062</td>\n",
       "      <td>376.411</td>\n",
       "      <td>2.1047</td>\n",
       "      <td>3.932</td>\n",
       "      <td>3.0</td>\n",
       "      <td>survey_medley</td>\n",
       "      <td>reverse</td>\n",
       "      <td>I have been obsessed with a certain idea or pr...</td>\n",
       "      <td>66,89,71,82,77</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>grit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>385411</td>\n",
       "      <td>s358</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>387.245</td>\n",
       "      <td>385.414</td>\n",
       "      <td>-1.7153</td>\n",
       "      <td>3.932</td>\n",
       "      <td>4.0</td>\n",
       "      <td>survey_medley</td>\n",
       "      <td>forward</td>\n",
       "      <td>Many opportunities await me in the future.</td>\n",
       "      <td>66,89,71,82,77</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>future_time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>399718</td>\n",
       "      <td>s358</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movement_onset    onset  response_time  duration  coded_response  \\\n",
       "35         350.213  348.452        -1.7853     3.932             4.0   \n",
       "36         362.048  357.727         0.7747     3.932             2.0   \n",
       "37         367.339  367.340        -3.5473     3.932             0.0   \n",
       "38         382.062  376.411         2.1047     3.932             3.0   \n",
       "39         387.245  385.414        -1.7153     3.932             4.0   \n",
       "\n",
       "   experiment_exp_id item_coding  \\\n",
       "35     survey_medley     reverse   \n",
       "36     survey_medley     forward   \n",
       "37     survey_medley     forward   \n",
       "38     survey_medley     reverse   \n",
       "39     survey_medley     forward   \n",
       "\n",
       "                                            item_text possible_responses  \\\n",
       "35                                         I am lazy.     66,89,71,82,77   \n",
       "36  Do you welcome new and exciting experiences an...              66,89   \n",
       "37  There is plenty of time left in my life to mak...     66,89,71,82,77   \n",
       "38  I have been obsessed with a certain idea or pr...     66,89,71,82,77   \n",
       "39         Many opportunities await me in the future.     66,89,71,82,77   \n",
       "\n",
       "    stim_duration             survey  text  time_elapsed worker_id   junk  \n",
       "35         8500.0              brief   NaN        357724      s358  False  \n",
       "36         8500.0  impulsive_venture   NaN        367339      s358  False  \n",
       "37         8500.0        future_time   NaN        376408      s358   True  \n",
       "38         8500.0               grit   NaN        385411      s358  False  \n",
       "39         8500.0        future_time   NaN        399718      s358  False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = task_list[0]\n",
    "subj = subject_list[0]\n",
    "bunch, contrasts = subjectinfo(data_dir, subj, task, False)\n",
    "events_df,confounds_df = subjectinfo(data_dir, subj, task,False,True)\n",
    "events_df.tail() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Input and Output Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get Subject Info - get subject specific condition information\n",
    "getsubjectinfo = Node(Function(input_names=['data_dir', 'subject_id',\n",
    "                                            'regress_rt', 'task'],\n",
    "                               output_names=['subject_info', 'contrasts'],\n",
    "                               function=subjectinfo),\n",
    "                      name='getsubjectinfo')\n",
    "getsubjectinfo.inputs.data_dir = data_dir\n",
    "getsubjectinfo.inputs.regress_rt = regress_rt\n",
    "# Infosource - a function free node to iterate over the list of subject names\n",
    "infosource = Node(IdentityInterface(fields=['subject_id',\n",
    "                                            'task',\n",
    "                                            'contrasts']),\n",
    "                  name=\"infosource\")\n",
    "infosource.iterables = [('subject_id', subject_list),\n",
    "                        ('task', task_list)]\n",
    "# SelectFiles - to grab the data (alternative to DataGrabber)\n",
    "templates = {'func': join('*{subject_id}','*','func',\n",
    "                         '*{task}*MNI*preproc.nii.gz'),\n",
    "            'mask': join('*{subject_id}','*','func',\n",
    "                         '*{task}*MNI*brainmask.nii.gz')}\n",
    "selectfiles = Node(SelectFiles(templates,\n",
    "                               base_directory = data_dir,\n",
    "                               sort_filelist=True),\n",
    "                   name=\"selectfiles\")\n",
    "# Datasink - creates output folder for important outputs\n",
    "datasink = Node(DataSink(base_directory = experiment_dir,\n",
    "                         container=output_dir),\n",
    "                name=\"datasink\")\n",
    "# Save python objects that aren't accomodated by datasink nodes\n",
    "save_subjectinfo = Node(Function(input_names=['base_directory','subject_id',\n",
    "                                              'task','subject_info','contrasts'],\n",
    "                                 output_names=['output_path'],\n",
    "                                function=save_subjectinfo),\n",
    "                       name=\"savesubjectinfo\")\n",
    "save_subjectinfo.inputs.base_directory = join(experiment_dir,output_dir)\n",
    "# Use the following DataSink output substitutions\n",
    "substitutions = [('_subject_id_', ''),\n",
    "                ('fstat', 'FSTST'),\n",
    "                ('run0.mat', 'designfile.mat')]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mask and blur\n",
    "masker = Node(fsl.maths.ApplyMask(),name='masker')\n",
    "\n",
    "# SpecifyModel - Generates FSL-specific Model\n",
    "modelspec = Node(SpecifyModel(input_units='secs',\n",
    "                              time_repetition=TR,\n",
    "                              high_pass_filter_cutoff=80),\n",
    "                 name=\"modelspec\")\n",
    "\n",
    "# Level1Design - Generates an FSL design matrix\n",
    "level1design = Node(fsl.Level1Design(bases={'dgamma':{'derivs': True}},\n",
    "                                 interscan_interval=TR,\n",
    "                                 model_serial_correlations=True),\n",
    "                    name=\"level1design\")\n",
    "\n",
    "# FEATmodel\n",
    "level1model = Node(fsl.FEATModel(), name=\"FEATModel\")\n",
    "\n",
    "# FILMGLs\n",
    "# smooth_autocorr, check default, use FSL default\n",
    "filmgls = Node(fsl.FILMGLS(), name=\"FILMGLS\")\n",
    "\n",
    "conestimate = Node(fsl.ContrastMgr(), name='conestimate',\n",
    "                      iterfield=['tcon_file', 'param_estimates',\n",
    "                                    'sigmasquareds', 'corrections',\n",
    "                                    'dof_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run as separate nodes\n",
    "\n",
    "Useful for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180104-13:12:17,197 workflow INFO:\n",
      "\t Executing node getsubjectinfo in dir: /tmp/tmpi3kdjjwx/getsubjectinfo\n",
      "180104-13:12:17,200 workflow INFO:\n",
      "\t Running node \"getsubjectinfo\" (\"nipype.interfaces.utility.wrappers.Function\").\n",
      "180104-13:12:17,301 workflow INFO:\n",
      "\t Executing node selectfiles in dir: /tmp/tmp7w1otneo/selectfiles\n",
      "180104-13:12:17,303 workflow INFO:\n",
      "\t Running node \"selectfiles\" (\"nipype.interfaces.io.SelectFiles\").\n"
     ]
    }
   ],
   "source": [
    "task = task_list[0]\n",
    "subj = subject_list[0]\n",
    "\n",
    "getsubjectinfo.inputs.subject_id = subj\n",
    "getsubjectinfo.inputs.task = task\n",
    "subject_info_out = getsubjectinfo.run()\n",
    "\n",
    "selectfiles.inputs.subject_id = subj\n",
    "selectfiles.inputs.task = task\n",
    "selectfiles_out = selectfiles.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180104-13:12:19,0 workflow INFO:\n",
      "\t Executing node masker in dir: /tmp/tmpfixchaih/masker\n",
      "180104-13:12:19,2 workflow INFO:\n",
      "\t Running node \"masker\" (\"nipype.interfaces.fsl.maths.ApplyMask\"), a CommandLine Interface with command:\n",
      "fslmaths /mnt/OAK/sub-s358/ses-2/func/sub-s358_ses-2_task-surveyMedley_run-1_bold_space-MNI152NLin2009cAsym_preproc.nii.gz -mas /mnt/OAK/sub-s358/ses-2/func/sub-s358_ses-2_task-surveyMedley_run-1_bold_space-MNI152NLin2009cAsym_brainmask.nii.gz /tmp/tmpfixchaih/masker/sub-s358_ses-2_task-surveyMedley_run-1_bold_space-MNI152NLin2009cAsym_preproc_masked.nii.gz.\n",
      "180104-13:12:56,871 workflow INFO:\n",
      "\t Executing node modelspec in dir: /tmp/tmpgqtsf192/modelspec\n",
      "180104-13:12:56,979 workflow INFO:\n",
      "\t Running node \"modelspec\" (\"nipype.algorithms.modelgen.SpecifyModel\").\n",
      "180104-13:12:57,186 workflow INFO:\n",
      "\t Executing node level1design in dir: /tmp/tmp2au7ggrt/level1design\n",
      "180104-13:12:57,395 workflow INFO:\n",
      "\t Running node \"level1design\" (\"nipype.interfaces.fsl.model.Level1Design\").\n",
      "180104-13:12:57,509 workflow INFO:\n",
      "\t Executing node FEATModel in dir: /tmp/tmpgn37l0b8/FEATModel\n",
      "180104-13:12:57,516 workflow INFO:\n",
      "\t Running node \"FEATModel\" (\"nipype.interfaces.fsl.model.FEATModel\"), a CommandLine Interface with command:\n",
      "feat_model run0 .\n"
     ]
    }
   ],
   "source": [
    "masker.inputs.in_file = selectfiles_out.outputs.func \n",
    "masker.inputs.mask_file = selectfiles_out.outputs.mask \n",
    "masker_out = masker.run()\n",
    "\n",
    "modelspec.inputs.subject_info = subject_info_out.outputs.subject_info \n",
    "modelspec.inputs.functional_runs = masker_out.outputs.out_file \n",
    "modelspec_out = modelspec.run()\n",
    "\n",
    "level1design.inputs.contrasts = subject_info_out.outputs.contrasts\n",
    "level1design.inputs.session_info = modelspec_out.outputs.session_info \n",
    "level1design_out = level1design.run() \n",
    "level1design_out.outputs\n",
    "\n",
    "level1model.inputs.fsf_file = level1design_out.outputs.fsf_files \n",
    "level1model.inputs.ev_files = level1design_out.outputs.ev_files \n",
    "out=level1model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180104-13:18:52,122 workflow INFO:\n",
      "\t Executing node FILMGLS in dir: /tmp/tmpa1nf6fgv/FILMGLS\n",
      "180104-13:18:52,125 workflow INFO:\n",
      "\t Running node \"FILMGLS\" (\"nipype.interfaces.fsl.model.FILMGLS\"), a CommandLine Interface with command:\n",
      "film_gls --rn=results --con=/tmp/tmpgn37l0b8/FEATModel/run0.con --in=/tmp/tmpfixchaih/masker/sub-s358_ses-2_task-surveyMedley_run-1_bold_space-MNI152NLin2009cAsym_preproc_masked.nii.gz --pd=/tmp/tmpgn37l0b8/FEATModel/run0.mat --thr=0.000000.\n",
      "180104-13:18:52,178 interface INFO:\n",
      "\t stdout 2018-01-04T13:18:52.178408:Log directory is: results\n",
      "180104-13:19:06,537 interface INFO:\n",
      "\t stdout 2018-01-04T13:19:06.537751:paradigm.getDesignMatrix().Nrows()=602\n",
      "180104-13:19:06,538 interface INFO:\n",
      "\t stdout 2018-01-04T13:19:06.537751:paradigm.getDesignMatrix().Ncols()=41\n",
      "180104-13:19:06,539 interface INFO:\n",
      "\t stdout 2018-01-04T13:19:06.537751:sizeTS=602\n",
      "180104-13:19:06,539 interface INFO:\n",
      "\t stdout 2018-01-04T13:19:06.537751:numTS=178367\n",
      "180104-13:19:06,613 interface INFO:\n",
      "\t stdout 2018-01-04T13:19:06.613802:Calculating residuals...\n",
      "180104-15:29:25,801 interface INFO:\n",
      "\t stdout 2018-01-04T15:29:25.801128:Completed\n",
      "180104-15:29:25,805 interface INFO:\n",
      "\t stdout 2018-01-04T15:29:25.801128:Estimating residual autocorrelation...\n",
      "180104-15:29:49,726 interface INFO:\n",
      "\t stdout 2018-01-04T15:29:49.726071:Calculating raw AutoCorrs... Completed\n",
      "180104-15:29:49,726 interface INFO:\n",
      "\t stdout 2018-01-04T15:29:49.726071:Tukey M = 24\n",
      "180104-15:29:50,564 interface INFO:\n",
      "\t stdout 2018-01-04T15:29:50.564225:Tukey estimates... Completed\n",
      "180104-15:29:50,564 interface INFO:\n",
      "\t stdout 2018-01-04T15:29:50.564225:Completed\n",
      "180104-15:29:50,565 interface INFO:\n",
      "\t stdout 2018-01-04T15:29:50.564225:Prewhitening and Computing PEs...\n",
      "180104-15:29:50,566 interface INFO:\n",
      "\t stdout 2018-01-04T15:29:50.564225:Percentage done:\n"
     ]
    }
   ],
   "source": [
    "filmgls.inputs.in_file = masker_out.outputs.out_file \n",
    "filmgls.inputs.design_file = out.outputs.design_file \n",
    "filmgls.inputs.tcon_file = out.outputs.con_file \n",
    "filmgls.inputs.fcon_file = out.outputs.fcon_file \n",
    "fil_out = filmgls.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conestimate.inputs.param_estimates = fil_out.outputs.param_estimates\n",
    "conestimate.inputs.sigmasquareds = fil_out.outputs.sigmasquareds\n",
    "conestimate.inputs.corrections = fil_out.outputs.corrections\n",
    "conestimate.inputs.dof_file = fil_out.outputs.dof_file\n",
    "\n",
    "conestimate.inputs.tcon_file = out.outputs.con_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasink.inputs.copes = fil_out.outputs.copes\n",
    "datasink.inputs.zstats = fil_out.outputs.zstats\n",
    "datasink.inputs.tstats = fil_out.outputs.tstats\n",
    "datasink.inputs.fstats = fil_out.outputs.fstats\n",
    "datasink.inputs.param_estimates = fil_out.outputs.param_estimates\n",
    "datasink.inputs.residual4d = fil_out.outputs.residual4d\n",
    "datasink.inputs.sigmasquareds = fil_out.outputs.sigmasquareds\n",
    "\n",
    "datasink.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_subjectinfo.inputs.subject_id = subj\n",
    "save_subjectinfo.inputs.task = task\n",
    "save_subjectinfo.inputs.subject_info = subject_info_out.outputs.subject_info\n",
    "save_subjectinfo.inputs.contrasts = subject_info_out.outputs.contrasts\n",
    "\n",
    "save_subjectinfo.run()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "desmtx=numpy.loadtxt(out.outputs.design_file,skiprows=5)\n",
    "plt.imshow(desmtx,aspect='auto',interpolation='nearest',cmap='gray')\n",
    "plt.title('Design Matrix')\n",
    "plt.show()\n",
    "cc=numpy.corrcoef(desmtx.T)\n",
    "plt.imshow(cc,aspect='auto',interpolation='nearest', cmap=plt.cm.viridis)\n",
    "plt.colorbar()\n",
    "plt.title('Correlation of Regressors')\n",
    "plt.show()\n",
    "# show first regressors\n",
    "plt.figure(figsize=[16,6])\n",
    "colors = ['m','c']\n",
    "for designi, conti in [(0,0),(2,1)]:\n",
    "    plt.plot(desmtx[:,designi], c=colors[conti], label=subject_info.conditions[conti])\n",
    "    ax = plt.gca()\n",
    "    for i in subject_info.onsets[conti]:\n",
    "        plt.axvline(i/.68, ymin=0, ymax=.1, c=colors[conti])\n",
    "plt.legend()\n",
    "plt.title('Incongruent Regressors')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import nilearn.plotting\n",
    "import nilearn.image\n",
    "\n",
    "nilearn.plotting.plot_glass_brain(nilearn.image.smooth_img(fil_out.outputs.zstats[0], 6),\n",
    "                                      display_mode='lyrz', colorbar=True, plot_abs=False, threshold=1)\n",
    "\n",
    "nilearn.plotting.plot_glass_brain(nilearn.image.smooth_img(fil_out.outputs.zstats[1], 6),\n",
    "                                      display_mode='lyrz', colorbar=True, plot_abs=False, threshold=1)\n",
    "\n",
    "nilearn.plotting.plot_glass_brain(nilearn.image.smooth_img(fil_out.outputs.zstats[2], 6),\n",
    "                                      display_mode='lyrz', colorbar=True, plot_abs=False, threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initiation of the 1st-level analysis workflow\n",
    "l1analysis = Workflow(name='l1analysis')\n",
    "l1analysis.base_dir = join(experiment_dir, working_dir)\n",
    "\n",
    "# Connect up the 1st-level analysis components\n",
    "l1analysis.connect([(infosource, selectfiles, [('subject_id', 'subject_id'),\n",
    "                                               ('task', 'task')]),\n",
    "                    (infosource, getsubjectinfo, [('subject_id','subject_id'),\n",
    "                                                 ('task', 'task')]),\n",
    "                    (selectfiles, masker, [('func','in_file'),\n",
    "                                           ('mask', 'mask_file')]),\n",
    "                    (getsubjectinfo, modelspec, [('subject_info','subject_info')]),\n",
    "                    (masker, modelspec, [('out_file', 'functional_runs')]),\n",
    "                    (modelspec, level1design, [('session_info','session_info')]),\n",
    "                    (getsubjectinfo, level1design, [('contrasts','contrasts')]),\n",
    "                    (level1design, level1model, [('ev_files', 'ev_files'),\n",
    "                                                 ('fsf_files','fsf_file')]),\n",
    "                    (masker, filmgls, [('out_file', 'in_file')]),\n",
    "                    (level1model, filmgls, [('design_file', 'design_file'),\n",
    "                                            ('con_file', 'tcon_file'),\n",
    "                                            ('fcon_file', 'fcon_file')]),\n",
    "                    (level1model, datasink, [('design_file', '1stLevel.@design_file')]),\n",
    "                    (filmgls, datasink, [('zstats', '1stLevel.@Z'),\n",
    "                                        ('fstats', '1stLevel.@F'),\n",
    "                                        ('tstats','1stLevel.@T'),\n",
    "                                        ('param_estimates','1stLevel.param_estimates')]),\n",
    "                    (infosource, save_subjectinfo, [('subject_id','subject_id'),\n",
    "                                                     ('task', 'task')]),\n",
    "                    (getsubjectinfo, save_subjectinfo, [('subject_info','subject_info'),\n",
    "                                                        ('contrasts','contrasts')]),\n",
    "                    \n",
    "                    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l1analysis.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create 1st-level analysis output graph\n",
    "l1analysis.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "# Visualize the graph\n",
    "from IPython.display import Image\n",
    "graph_file=join(l1analysis.base_dir, 'l1analysis', 'graph.dot.png')\n",
    "Image(graph_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.move(graph_file, 'l1analysis')\n",
    "except shutil.Error:\n",
    "    pass\n",
    "# remove working directory\n",
    "shutil.rmtree(working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Design Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tree datasink/1stLevel/sub*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "design_file = glob(join(experiment_dir,'datasink','1stLevel','sub-s358_task_CCTHot','designfile.mat'))[0]\n",
    "desmtx=numpy.loadtxt(design_file, skiprows=5)\n",
    "plt.imshow(desmtx,aspect='auto',interpolation='nearest',cmap='gray')\n",
    "plt.title('Design Matrix')\n",
    "plt.show()\n",
    "cc=numpy.corrcoef(desmtx.T)\n",
    "plt.imshow(cc,aspect='auto',interpolation='nearest', cmap=plt.cm.viridis)\n",
    "plt.colorbar()\n",
    "plt.title('Correlation of Regressors')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "# show first regressors\n",
    "plt.figure(figsize=[20,8])\n",
    "plt.plot(desmtx[:,0],'b', label=subject_info.conditions[0])\n",
    "plt.plot(desmtx[:,2],'r', label=subject_info.conditions[1])\n",
    "for i in subject_info.onsets[0]:\n",
    "    plt.axvline(i/.68, ymin=0, ymax=.1)\n",
    "for i in subject_info.onsets[1]:\n",
    "    plt.axvline(i/.68, ymin=0, ymax=.1, c='r')\n",
    "plt.legend()\n",
    "plt.title('Congruent/Incongruent Regressors')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map\n",
    "from nilearn.image import smooth_img\n",
    "\n",
    "anatimg = glob(join(experiment_dir,'Data','sub-s358','anat','*T1w*MNI*preproc*'))[0]\n",
    "contrast_img = glob(join(experiment_dir,'datasink','1stLevel','sub-s358_task_ANT','zstat3.nii.gz'))[0]\n",
    "plot_stat_map(smooth_img(contrast_img, 8), title='stroop effect',\n",
    "              bg_img=anatimg, threshold=1, display_mode='z', cut_coords=(-30, -15, 0, 15, 30), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nilearn.plotting\n",
    "import nilearn.image\n",
    "import cPickle\n",
    "\n",
    "for task in task_list:\n",
    "    contrast_file = glob(join(experiment_dir,'datasink','1stLevel','sub-s358_task_' + task,'contrasts.pkl'))[0]\n",
    "    contrasts = cPickle.load(open(contrast_file,'r'))\n",
    "    contrasts = [contrast[0] for contrast in contrasts]\n",
    "    contrast_imgs = sort(glob(join(experiment_dir,'datasink','1stLevel','sub-s358_task_' + task,'zstat*.nii.gz')))\n",
    "    for i, contrast_img in enumerate(contrast_imgs):\n",
    "        nilearn.plotting.plot_glass_brain(nilearn.image.smooth_img(contrast_img, 8),\n",
    "                                          display_mode='lyrz', colorbar=True, plot_abs=False, threshold=0,\n",
    "                                          title=contrasts[i])\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "243px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
