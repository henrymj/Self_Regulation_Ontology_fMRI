{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from glob import glob\n",
    "from nipype.interfaces import afni\n",
    "from nipype.interfaces.fsl import Level1Design, FEATModel, FILMGLS, FEAT, maths\n",
    "from nipype.algorithms.modelgen import SpecifyModel\n",
    "from nipype.interfaces.utility import Function, IdentityInterface\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.pipeline.engine import Workflow, Node\n",
    "from os import makedirs\n",
    "from os.path import abspath, join\n",
    "import pandas as pd\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Experiment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment_dir = abspath('.')\n",
    "output_dir = 'datasink'\n",
    "working_dir = 'workingdir'\n",
    "\n",
    "# list of subject identifiers\n",
    "subject_list = ['sub-s358']\n",
    "\n",
    "# list of task identifiers\n",
    "task_list = ['ANT', 'DPX', 'stroop', 'twoByTwo']\n",
    "task_list = ['WATT3']\n",
    "\n",
    "# TR of functional images\n",
    "TR = .68\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Set up Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# helper function to create bunch\n",
    "def subjectinfo(subject_id, task, inspect_inputs=False):\n",
    "    \n",
    "    from glob import glob\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from os.path import join\n",
    "    from nipype.interfaces.base import Bunch\n",
    "    from utils.utils import get_contrasts, parse_EVs, process_confounds\n",
    "    \n",
    "    base_dir = '/home/jovyan/work/output'\n",
    "    \n",
    "    # strip \"sub\" from beginning of subject_id if provided\n",
    "    subject_id = subject_id.replace('sub-','')\n",
    "    \n",
    "    ## Get the Events File\n",
    "    \n",
    "    # Read the TSV file and convert to pandas dataframe\n",
    "    event_file = glob(join(base_dir,\n",
    "                           'Data',\n",
    "                           'sub-%s' % subject_id,\n",
    "                           '*', 'func',\n",
    "                           '*%s*events.tsv' % task))[0]\n",
    "    events_df = pd.read_csv(event_file,sep = '\\t')\n",
    "\n",
    "    ## Get the Confounds File (output of fmriprep)\n",
    "    # Read the TSV file and convert to pandas dataframe\n",
    "    confounds_file = glob(join(base_dir,\n",
    "                               'Data',\n",
    "                               'sub-%s' % subject_id,\n",
    "                               '*', 'func',\n",
    "                               '*%s*confounds.tsv' % task))[0]\n",
    "    regressors, regressor_names = process_confounds(confounds_file)\n",
    "    \n",
    "    # set up contrasts\n",
    "    conditions, onsets, durations, amplitudes = parse_EVs(events_df,task)\n",
    "    \n",
    "    subjectinfo = Bunch(conditions=conditions,\n",
    "                        onsets=onsets,\n",
    "                         durations=durations,\n",
    "                         amplitudes=amplitudes,\n",
    "                         tmod=None,\n",
    "                         pmod=None,\n",
    "                         regressor_names=regressor_names,\n",
    "                         regressors=regressors.T.tolist())\n",
    "    if inspect_inputs==True:\n",
    "        regressors_df = pd.DataFrame(regressors, columns = regressor_names)\n",
    "        return events_df, regressors_df\n",
    "    else:\n",
    "        contrasts = get_contrasts(task)\n",
    "        return subjectinfo, contrasts  # this output will later be returned to infosource\n",
    "\n",
    "def save_subjectinfo(base_directory, subject_id, task, subject_info, contrasts):\n",
    "    import errno\n",
    "    from os import makedirs\n",
    "    from os.path import join\n",
    "    import cPickle\n",
    "    task_dir = join(base_directory, '1stLevel', subject_id + '_task_' + task)\n",
    "    try: \n",
    "        makedirs(task_dir)\n",
    "    except OSError as e:\n",
    "        if e.errno == errno.EEXIST:\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "    subjectinfo_path = join(task_dir,'subjectinfo.pkl')\n",
    "    cPickle.dump(subject_info, open(subjectinfo_path,'w'))\n",
    "    \n",
    "    contrast_path = join(task_dir,'contrasts.pkl')\n",
    "    cPickle.dump(contrasts, open(contrast_path,'w'))\n",
    "    return (subjectinfo_path, contrast_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "View one events file used in subject info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>block_duration</th>\n",
       "      <th>planning</th>\n",
       "      <th>condition</th>\n",
       "      <th>experiment_exp_id</th>\n",
       "      <th>key_press</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>worker_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.008</td>\n",
       "      <td>5.1102</td>\n",
       "      <td>4737.0</td>\n",
       "      <td>1</td>\n",
       "      <td>UA_with_intermeidate</td>\n",
       "      <td>ward_and_allport</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>s358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.746</td>\n",
       "      <td>5.7310</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>0</td>\n",
       "      <td>UA_with_intermeidate</td>\n",
       "      <td>ward_and_allport</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>s358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.724</td>\n",
       "      <td>5.1102</td>\n",
       "      <td>8030.0</td>\n",
       "      <td>1</td>\n",
       "      <td>UA_with_intermeidate</td>\n",
       "      <td>ward_and_allport</td>\n",
       "      <td>89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>s358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.755</td>\n",
       "      <td>5.7310</td>\n",
       "      <td>547.0</td>\n",
       "      <td>0</td>\n",
       "      <td>UA_with_intermeidate</td>\n",
       "      <td>ward_and_allport</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>s358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.620</td>\n",
       "      <td>5.1102</td>\n",
       "      <td>4796.0</td>\n",
       "      <td>1</td>\n",
       "      <td>UA_without_intermeidate</td>\n",
       "      <td>ward_and_allport</td>\n",
       "      <td>82</td>\n",
       "      <td>2.0</td>\n",
       "      <td>s358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    onset  duration  block_duration  planning                condition  \\\n",
       "0   3.008    5.1102          4737.0         1     UA_with_intermeidate   \n",
       "1   7.746    5.7310          1603.0         0     UA_with_intermeidate   \n",
       "2  14.724    5.1102          8030.0         1     UA_with_intermeidate   \n",
       "3  22.755    5.7310           547.0         0     UA_with_intermeidate   \n",
       "4  27.620    5.1102          4796.0         1  UA_without_intermeidate   \n",
       "\n",
       "  experiment_exp_id  key_press  problem_id worker_id  \n",
       "0  ward_and_allport         71         0.0      s358  \n",
       "1  ward_and_allport         82         0.0      s358  \n",
       "2  ward_and_allport         89         1.0      s358  \n",
       "3  ward_and_allport         82         1.0      s358  \n",
       "4  ward_and_allport         82         2.0      s358  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bunch, contrasts = subjectinfo('s358','WATT3')\n",
    "events_df,confounds_df = subjectinfo('s358','WATT3',True)\n",
    "events_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Specify Input and Output Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get Subject Info - get subject specific condition information\n",
    "getsubjectinfo = Node(Function(input_names=['subject_id', 'task'],\n",
    "                               output_names=['subject_info', 'contrasts'],\n",
    "                               function=subjectinfo),\n",
    "                      name='getsubjectinfo')\n",
    "\n",
    "# Infosource - a function free node to iterate over the list of subject names\n",
    "infosource = Node(IdentityInterface(fields=['subject_id',\n",
    "                                            'task',\n",
    "                                            'contrasts']),\n",
    "                  name=\"infosource\")\n",
    "infosource.iterables = [('subject_id', subject_list),\n",
    "                        ('task', task_list)]\n",
    "\n",
    "# SelectFiles - to grab the data (alternativ to DataGrabber)\n",
    "templates = {'func': join('Data', '{subject_id}','*','func',\n",
    "                         '*{task}*preproc.nii.gz'),\n",
    "            'mask': join('Data', '{subject_id}','*','func',\n",
    "                         '*{task}*brainmask.nii.gz')}\n",
    "selectfiles = Node(SelectFiles(templates,\n",
    "                               base_directory = experiment_dir,\n",
    "                               sort_filelist=True),\n",
    "                   name=\"selectfiles\")\n",
    "\n",
    "# Datasink - creates output folder for important outputs\n",
    "datasink = Node(DataSink(base_directory = experiment_dir,\n",
    "                         container=output_dir),\n",
    "                name=\"datasink\")\n",
    "\n",
    "# Save python objects that aren't accomodated by datasink nodes\n",
    "save_subjectinfo = Node(Function(input_names=['base_directory','subject_id',\n",
    "                                              'task','subject_info','contrasts'],\n",
    "                                 output_names=['output_path'],\n",
    "                                function=save_subjectinfo),\n",
    "                       name=\"savesubjectinfo\")\n",
    "save_subjectinfo.inputs.base_directory = join(experiment_dir,output_dir)\n",
    "# Use the following DataSink output substitutions\n",
    "substitutions = [('_subject_id_', ''),\n",
    "                ('fstat', 'FSTST'),\n",
    "                ('run0.mat', 'designfile.mat')]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mask and blur\n",
    "masker = Node(maths.ApplyMask(),name='masker')\n",
    "\n",
    "# SpecifyModel - Generates FSL-specific Model\n",
    "modelspec = Node(SpecifyModel(input_units='secs',\n",
    "                              time_repetition=TR,\n",
    "                              high_pass_filter_cutoff=80),\n",
    "                 name=\"modelspec\")\n",
    "\n",
    "# Level1Design - Generates an FSL design matrix\n",
    "level1design = Node(Level1Design(bases={'dgamma':{'derivs': True}},\n",
    "                                 interscan_interval=TR,\n",
    "                                 model_serial_correlations=True),\n",
    "                    name=\"level1design\")\n",
    "\n",
    "# FEATmodel\n",
    "level1model = Node(FEATModel(), name=\"FEATModel\")\n",
    "\n",
    "# FILMGLs\n",
    "# smooth_autocorr, check default, use FSL default\n",
    "filmgls = Node(FILMGLS(), name=\"FILMGLS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Run as separate nodes\n",
    "\n",
    "Useful for debugging"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "source": [
    "task = 'WATT3'\n",
    "getsubjectinfo.inputs.subject_id = 'sub-s358' \n",
    "getsubjectinfo.inputs.task = task\n",
    "subject_info_out = getsubjectinfo.run()\n",
    "subject_info = subject_info_out.outputs.subject_info\n",
    "\n",
    "selectfiles.inputs.subject_id = 'sub-s358' \n",
    "selectfiles.inputs.task = task\n",
    "selectfiles_out = selectfiles.run()\n",
    "\n",
    "masker.inputs.in_file = selectfiles_out.outputs.func \n",
    "masker.inputs.mask_file = selectfiles_out.outputs.mask \n",
    "masker_out = masker.run()\n",
    "\n",
    "modelspec.inputs.subject_info = subject_info \n",
    "modelspec.inputs.functional_runs = masker_out.outputs.out_file \n",
    "modelspec_out = modelspec.run()\n",
    "\n",
    "level1design.inputs.contrasts = subject_info_out.outputs.contrasts\n",
    "level1design.inputs.session_info = modelspec_out.outputs.session_info \n",
    "level1design_out = level1design.run() \n",
    "level1design_out.outputs\n",
    "\n",
    "level1model.inputs.fsf_file = level1design_out.outputs.fsf_files \n",
    "level1model.inputs.ev_files = level1design_out.outputs.ev_files \n",
    "out=level1model.run()\n",
    "\n",
    "#filmgls.inputs.in_file = masker_out.outputs.out_file \n",
    "#filmgls.inputs.design_file = out.outputs.design_file \n",
    "#filmgls.inputs.tcon_file = out.outputs.con_file \n",
    "#filmgls.inputs.fcon_file = out.outputs.fcon_file \n",
    "#fil_out = filmgls.run()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "desmtx=numpy.loadtxt(out.outputs.design_file,skiprows=5)\n",
    "plt.imshow(desmtx,aspect='auto',interpolation='nearest',cmap='gray')\n",
    "plt.title('Design Matrix')\n",
    "plt.show()\n",
    "cc=numpy.corrcoef(desmtx.T)\n",
    "plt.imshow(cc,aspect='auto',interpolation='nearest', cmap=plt.cm.viridis)\n",
    "plt.colorbar()\n",
    "plt.title('Correlation of Regressors')\n",
    "plt.show()\n",
    "# show first regressors\n",
    "plt.figure(figsize=[16,6])\n",
    "colors = ['m','c']\n",
    "for designi, conti in [(0,0),(2,1)]:\n",
    "    plt.plot(desmtx[:,designi], c=colors[conti], label=subject_info.conditions[conti])\n",
    "    ax = plt.gca()\n",
    "    for i in subject_info.onsets[conti]:\n",
    "        plt.axvline(i/.68, ymin=0, ymax=.1, c=colors[conti])\n",
    "plt.legend()\n",
    "plt.title('Incongruent Regressors')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "import nilearn.plotting\n",
    "import nilearn.image\n",
    "\n",
    "nilearn.plotting.plot_glass_brain(nilearn.image.smooth_img(fil_out.outputs.zstats[0], 6),\n",
    "                                      display_mode='lyrz', colorbar=True, plot_abs=False, threshold=1)\n",
    "\n",
    "nilearn.plotting.plot_glass_brain(nilearn.image.smooth_img(fil_out.outputs.zstats[1], 6),\n",
    "                                      display_mode='lyrz', colorbar=True, plot_abs=False, threshold=1)\n",
    "\n",
    "nilearn.plotting.plot_glass_brain(nilearn.image.smooth_img(fil_out.outputs.zstats[2], 6),\n",
    "                                      display_mode='lyrz', colorbar=True, plot_abs=False, threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initiation of the 1st-level analysis workflow\n",
    "l1analysis = Workflow(name='l1analysis')\n",
    "l1analysis.base_dir = join(experiment_dir, working_dir)\n",
    "\n",
    "# Connect up the 1st-level analysis components\n",
    "l1analysis.connect([(infosource, selectfiles, [('subject_id', 'subject_id'),\n",
    "                                               ('task', 'task')]),\n",
    "                    (infosource, getsubjectinfo, [('subject_id','subject_id'),\n",
    "                                                 ('task', 'task')]),\n",
    "                    (selectfiles, masker, [('func','in_file'),\n",
    "                                           ('mask', 'mask_file')]),\n",
    "                    (getsubjectinfo, modelspec, [('subject_info','subject_info')]),\n",
    "                    (masker, modelspec, [('out_file', 'functional_runs')]),\n",
    "                    (modelspec, level1design, [('session_info','session_info')]),\n",
    "                    (getsubjectinfo, level1design, [('contrasts','contrasts')]),\n",
    "                    (level1design, level1model, [('ev_files', 'ev_files'),\n",
    "                                                 ('fsf_files','fsf_file')]),\n",
    "                    (masker, filmgls, [('out_file', 'in_file')]),\n",
    "                    (level1model, filmgls, [('design_file', 'design_file'),\n",
    "                                            ('con_file', 'tcon_file'),\n",
    "                                            ('fcon_file', 'fcon_file')]),\n",
    "                    (level1model, datasink, [('design_file', '1stLevel.@design_file')]),\n",
    "                    (filmgls, datasink, [('zstats', '1stLevel.@Z'),\n",
    "                                        ('fstats', '1stLevel.@F'),\n",
    "                                        ('tstats','1stLevel.@T'),\n",
    "                                        ('param_estimates','1stLevel.param_estimates')]),\n",
    "                    (infosource, save_subjectinfo, [('subject_id','subject_id'),\n",
    "                                                     ('task', 'task')]),\n",
    "                    (getsubjectinfo, save_subjectinfo, [('subject_info','subject_info'),\n",
    "                                                        ('contrasts','contrasts')]),\n",
    "                    \n",
    "                    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Run the Workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170531-17:45:42,381 workflow INFO:\n",
      "\t Workflow l1analysis settings: ['check', 'execution', 'logging']\n",
      "170531-17:45:42,393 workflow INFO:\n",
      "\t Running in parallel.\n",
      "170531-17:45:42,396 workflow INFO:\n",
      "\t Executing: getsubjectinfo.a0 ID: 0\n",
      "170531-17:45:42,397 workflow INFO:\n",
      "\t [Job finished] jobname: getsubjectinfo.a0 jobid: 0\n",
      "170531-17:45:42,399 workflow INFO:\n",
      "\t Executing: selectfiles.a0 ID: 1\n",
      "170531-17:45:42,403 workflow INFO:\n",
      "\t Executing node selectfiles.a0 in dir: /home/jovyan/work/output/workingdir/l1analysis/_subject_id_sub-s358_task_WATT3/selectfiles\n",
      "170531-17:45:42,433 workflow INFO:\n",
      "\t [Job finished] jobname: selectfiles.a0 jobid: 1\n",
      "170531-17:45:42,435 workflow INFO:\n",
      "\t Executing: masker.a0 ID: 2\n",
      "170531-17:45:42,439 workflow INFO:\n",
      "\t [Job finished] jobname: masker.a0 jobid: 2\n",
      "170531-17:45:42,440 workflow INFO:\n",
      "\t Executing: savesubjectinfo.a0 ID: 5\n",
      "170531-17:45:42,740 workflow INFO:\n",
      "\t [Job finished] jobname: savesubjectinfo.a0 jobid: 5\n",
      "170531-17:45:42,742 workflow INFO:\n",
      "\t Executing: modelspec.a0 ID: 3\n",
      "170531-17:45:42,944 workflow INFO:\n",
      "\t [Job finished] jobname: modelspec.a0 jobid: 3\n",
      "170531-17:45:42,946 workflow INFO:\n",
      "\t Executing: level1design.a0 ID: 4\n",
      "170531-17:45:43,788 workflow INFO:\n",
      "\t [Job finished] jobname: level1design.a0 jobid: 4\n",
      "170531-17:45:43,791 workflow INFO:\n",
      "\t Executing: FEATModel.a0 ID: 6\n",
      "170531-17:45:44,46 workflow INFO:\n",
      "\t Executing node FEATModel.a0 in dir: /home/jovyan/work/output/workingdir/l1analysis/_subject_id_sub-s358_task_WATT3/FEATModel\n",
      "170531-17:45:44,74 workflow INFO:\n",
      "\t Running: feat_model run0 \n",
      "170531-17:45:46,409 workflow INFO:\n",
      "\t [Job finished] jobname: FEATModel.a0 jobid: 6\n",
      "170531-17:45:46,411 workflow INFO:\n",
      "\t Executing: FILMGLS.a0 ID: 7\n",
      "170531-17:45:46,425 workflow INFO:\n",
      "\t Executing node FILMGLS.a0 in dir: /home/jovyan/work/output/workingdir/l1analysis/_subject_id_sub-s358_task_WATT3/FILMGLS\n",
      "170531-17:45:46,431 workflow ERROR:\n",
      "\t [u'Node FILMGLS.a0 failed to run on host 84630236578b.']\n",
      "170531-17:45:46,431 workflow INFO:\n",
      "\t Saving crash info to /home/jovyan/work/output/crash-20170531-174546-jovyan-FILMGLS.a0-2deac3b5-ce2d-4f17-8a4d-894e06404c56.pklz\n",
      "170531-17:45:46,432 workflow INFO:\n",
      "\t Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/pipeline/plugins/multiproc.py\", line 52, in run_node\n",
      "    result['result'] = node.run(updatehash=updatehash)\n",
      "  File \"/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/pipeline/engine/nodes.py\", line 347, in run\n",
      "    raise ex\n",
      "OSError: [Errno 39] Directory not empty: '/home/jovyan/work/output/workingdir/l1analysis/_subject_id_sub-s358_task_WATT3/FILMGLS/results'\n",
      "\n",
      "170531-17:45:46,438 workflow INFO:\n",
      "\t ***********************************\n",
      "170531-17:45:46,439 workflow ERROR:\n",
      "\t could not run node: l1analysis.FILMGLS.a0\n",
      "170531-17:45:46,439 workflow INFO:\n",
      "\t crashfile: /home/jovyan/work/output/crash-20170531-174546-jovyan-FILMGLS.a0-2deac3b5-ce2d-4f17-8a4d-894e06404c56.pklz\n",
      "170531-17:45:46,440 workflow INFO:\n",
      "\t ***********************************\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Workflow did not execute cleanly. Check log for details",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5eb76c2ecef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml1analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MultiProc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'n_procs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/pipeline/engine/workflows.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_report'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0mdatestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%dT%H%M%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'write_provenance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/pipeline/plugins/base.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_node_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mreport_nodes_not_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# close any open resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/pipeline/plugins/base.pyc\u001b[0m in \u001b[0;36mreport_nodes_not_run\u001b[0;34m(notrun)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***********************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise RuntimeError(('Workflow did not execute cleanly. '\n\u001b[0m\u001b[1;32m     96\u001b[0m                             'Check log for details'))\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Workflow did not execute cleanly. Check log for details"
     ]
    }
   ],
   "source": [
    "l1analysis.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualize Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create 1st-level analysis output graph\n",
    "l1analysis.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "# Visualize the graph\n",
    "from IPython.display import Image\n",
    "graph_file=join(l1analysis.base_dir, 'l1analysis', 'graph.dot.png')\n",
    "Image(graph_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-203187d9cc67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l1analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# remove working directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graph_file' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    shutil.move(graph_file, 'l1analysis')\n",
    "except shutil.Error:\n",
    "    pass\n",
    "# remove working directory\n",
    "shutil.rmtree(working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualize Design Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tree datasink/1stLevel/sub*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "design_file = glob(join(experiment_dir,'datasink','1stLevel','sub-s358_task_ANT','designfile.mat'))[0]\n",
    "desmtx=numpy.loadtxt(design_file, skiprows=5)\n",
    "plt.imshow(desmtx,aspect='auto',interpolation='nearest',cmap='gray')\n",
    "plt.title('Design Matrix')\n",
    "plt.show()\n",
    "cc=numpy.corrcoef(desmtx.T)\n",
    "plt.imshow(cc,aspect='auto',interpolation='nearest', cmap=plt.cm.viridis)\n",
    "plt.colorbar()\n",
    "plt.title('Correlation of Regressors')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "# show first regressors\n",
    "plt.figure(figsize=[20,8])\n",
    "plt.plot(desmtx[:,0],'b', label=subject_info.conditions[0])\n",
    "plt.plot(desmtx[:,2],'r', label=subject_info.conditions[1])\n",
    "for i in subject_info.onsets[0]:\n",
    "    plt.axvline(i/.68, ymin=0, ymax=.1)\n",
    "for i in subject_info.onsets[1]:\n",
    "    plt.axvline(i/.68, ymin=0, ymax=.1, c='r')\n",
    "plt.legend()\n",
    "plt.title('Congruent/Incongruent Regressors')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map\n",
    "from nilearn.image import smooth_img\n",
    "\n",
    "anatimg = glob(join(experiment_dir,'Data','sub-s358','anat','*T1w*MNI*preproc*'))[0]\n",
    "contrast_img = glob(join(experiment_dir,'datasink','1stLevel','sub-s358_task_ANT','zstat3.nii.gz'))[0]\n",
    "plot_stat_map(smooth_img(contrast_img, 8), title='stroop effect',\n",
    "              bg_img=anatimg, threshold=1, display_mode='z', cut_coords=(-30, -15, 0, 15, 30), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nilearn.plotting\n",
    "import nilearn.image\n",
    "contrast_imgs = sort(glob(join(experiment_dir,'datasink','1stLevel','sub-s358_task_ANT','zstat*.nii.gz')))\n",
    "for contrast_img in contrast_imgs:\n",
    "    nilearn.plotting.plot_glass_brain(nilearn.image.smooth_img(contrast_img, 8),\n",
    "                                      display_mode='lyrz', colorbar=True, plot_abs=False, threshold=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
