{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pt0.5 - imports and (mounted) paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from os import path,makedirs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_dir = '/Users/henrymj/Documents/SRO/tmp/OAK/data/uh2/aim1/BIDS_scans'\n",
    "deriv_dir = path.join(bids_dir, 'derivatives')\n",
    "firstlevel_path = path.join(deriv_dir, '1stlevel')\n",
    "fsl_input_path = path.join(deriv_dir, 'fsl/inputs')\n",
    "fsl_output_path = path.join(deriv_dir, 'fsl/outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making some dirs that I didn't get around to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_fsl_dirs = glob(path.join(fsl_output_path, 's*', '*'))\n",
    "curr_fsl_dirs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dpath in curr_fsl_dirs:\n",
    "    if path.isdir(dpath):\n",
    "        print(dpath)\n",
    "        makedirs(path.join(dpath, 'RT-True'), exist_ok=True)\n",
    "        makedirs(path.join(dpath, 'RT-False'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pt1 - making simple events .tsv files for design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsfiles = glob(path.join(firstlevel_path, '*/*', 'simplified_events_RT-True_*')) #the RT regressor does not affect the calculation of other regressors\n",
    "eventsfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ef in eventsfiles:\n",
    "    subjtask = ef.split('1stlevel/')[1].split('/simplified')[0] #get subj/task\n",
    "    makedirs(path.join(fsl_input_path, subjtask), exist_ok=True) #make fsl/inputs/subj/task dir\n",
    "    makedirs(path.join(fsl_output_path, subjtask), exist_ok=True) #make fsl/inputs/subj/task dir\n",
    "    ev_df = pd.read_csv(ef)\n",
    "    curr_conditions = ev_df.conditions.unique()\n",
    "    for cond in curr_conditions:\n",
    "        tmp = ev_df[ev_df.conditions==cond] #get condition subset\n",
    "        tmp = tmp.filter(['onsets', 'durations', 'amplitudes']) #drop irrelevant columns\n",
    "        tmp.to_csv(path.join(fsl_input_path, subjtask, cond+'_events.tsv'), sep='\\t', header=False, index=False) #save as simple tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pt2 - making confound .tsv files for design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "confound_cols = ['trans_*', 'rot_*', 'framewise_displacement', 'a_comp_cor_*', 'rejectTR_*', 'drift_*', 'constant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "designfiles = glob(path.join(firstlevel_path, '*/*', 'design_RT-True*')) #confounds should not be affected by presence/absence of RT regressor\n",
    "designfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for des in designfiles:\n",
    "    subjtask = des.split('1stlevel/')[1].split('/design')[0] #get subj/task\n",
    "    makedirs(path.join(fsl_input_path, subjtask), exist_ok=True) #make fsl/inputs/subj/task dir\n",
    "    des_df = pd.read_csv(des, index_col=0)\n",
    "    confound_df = des_df.filter(regex='|'.join(confound_cols))\n",
    "    confound_df.to_csv(path.join(fsl_input_path, subjtask, 'confounds.tsv'), sep='\\t', header=False, index=False) #save as simple tsv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z', 'trans_xtd',\n",
       "       'trans_ytd', 'trans_ztd', 'rot_xtd', 'rot_ytd', 'rot_ztd', 'trans_x_sq',\n",
       "       'trans_y_sq', 'trans_z_sq', 'rot_x_sq', 'rot_y_sq', 'rot_z_sq',\n",
       "       'trans_xtd_sq', 'trans_ytd_sq', 'trans_ztd_sq', 'rot_xtd_sq',\n",
       "       'rot_ytd_sq', 'rot_ztd_sq', 'framewise_displacement', 'a_comp_cor_00',\n",
       "       'a_comp_cor_01', 'a_comp_cor_02', 'a_comp_cor_03', 'a_comp_cor_04',\n",
       "       'a_comp_cor_05', 'a_comp_cor_06', 'a_comp_cor_07', 'rejectTR_99',\n",
       "       'rejectTR_136', 'rejectTR_211', 'rejectTR_212', 'rejectTR_271',\n",
       "       'rejectTR_330', 'rejectTR_427', 'rejectTR_498', 'rejectTR_502',\n",
       "       'rejectTR_676', 'rejectTR_681', 'rejectTR_694', 'rejectTR_803',\n",
       "       'rejectTR_872', 'rejectTR_877', 'rejectTR_946', 'rejectTR_947',\n",
       "       'rejectTR_955', 'rejectTR_956', 'rejectTR_969', 'rejectTR_970',\n",
       "       'rejectTR_971', 'rejectTR_972', 'rejectTR_980', 'rejectTR_981',\n",
       "       'rejectTR_982', 'rejectTR_1002', 'rejectTR_1003', 'rejectTR_1004',\n",
       "       'rejectTR_1005', 'drift_1', 'drift_2', 'drift_3', 'drift_4', 'drift_5',\n",
       "       'drift_6', 'drift_7', 'drift_8', 'drift_9', 'drift_10', 'drift_11',\n",
       "       'drift_12', 'drift_13', 'drift_14', 'drift_15', 'drift_16', 'constant'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confound_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pt3 - generate slicetiming files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_jsons = glob(path.join(bids_dir, '*_bold.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/henrymj/Documents/SRO/tmp/OAK/data/uh2/aim1/BIDS_scans/derivatives/fsl/inputs/stroop_slice_times.txt\n",
      "/Users/henrymj/Documents/SRO/tmp/OAK/data/uh2/aim1/BIDS_scans/derivatives/fsl/inputs/motorSelectiveStop_slice_times.txt\n",
      "/Users/henrymj/Documents/SRO/tmp/OAK/data/uh2/aim1/BIDS_scans/derivatives/fsl/inputs/rest_slice_times.txt\n",
      "/Users/henrymj/Documents/SRO/tmp/OAK/data/uh2/aim1/BIDS_scans/derivatives/fsl/inputs/twoByTwo_slice_times.txt\n",
      "/Users/henrymj/Documents/SRO/tmp/OAK/data/uh2/aim1/BIDS_scans/derivatives/fsl/inputs/discountFix_slice_times.txt\n",
      "/Users/henrymj/Documents/SRO/tmp/OAK/data/uh2/aim1/BIDS_scans/derivatives/fsl/inputs/CCTHot_slice_times.txt\n",
      "/Users/henrymj/Documents/SRO/tmp/OAK/data/uh2/aim1/BIDS_scans/derivatives/fsl/inputs/ANT_slice_times.txt\n",
      "/Users/henrymj/Documents/SRO/tmp/OAK/data/uh2/aim1/BIDS_scans/derivatives/fsl/inputs/DPX_slice_times.txt\n",
      "/Users/henrymj/Documents/SRO/tmp/OAK/data/uh2/aim1/BIDS_scans/derivatives/fsl/inputs/surveyMedley_slice_times.txt\n",
      "/Users/henrymj/Documents/SRO/tmp/OAK/data/uh2/aim1/BIDS_scans/derivatives/fsl/inputs/stopSignal_slice_times.txt\n",
      "/Users/henrymj/Documents/SRO/tmp/OAK/data/uh2/aim1/BIDS_scans/derivatives/fsl/inputs/WATT3_slice_times.txt\n"
     ]
    }
   ],
   "source": [
    "for curr_json in task_jsons:\n",
    "    #read in json dict\n",
    "    jf = open(curr_json,'r')\n",
    "    task_dict = JSON.loads(jf.read())\n",
    "    jf.close()\n",
    "    #get relevant path\n",
    "    task_str = curr_json.split('task-')[1].replace('_bold.json', '')\n",
    "    out_slice_file = path.join(fsl_input_path, task_str+'_slice_times.txt')\n",
    "    #write the slice times into a file\n",
    "    f=open(out_slice_file, 'w+')\n",
    "    for slice_time in task_dict['SliceTiming']:\n",
    "        f.write(str(slice_time)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pt4 - extract brains\n",
    "\n",
    "this will generate commands like the one below and save them to an sbatch_file in SRO_fMRI/fmri_analyses/fsl\n",
    "\n",
    "`/share/software/user/open/fsl/5.0.10/bin/bet /oak/stanford/groups/russpold/data/uh2/aim1/BIDS_scans/sub-s061/ses-1/anat/sub-s061_ses-1_T1w /oak/stanford/groups/russpold/data/uh2/aim1/BIDS_scans/derivatives/fsl/inputs/s061/brain  -f 0.5 -g 0 -m\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbatch_headers='''#!/bin/bash\n",
    "#SBATCH --job-name=fsl_BET\n",
    "#SBATCH --output=.out/fsl_BET.out\n",
    "#SBATCH --error=.err/fsl_BET.err\n",
    "#SBATCH --time=10:00:00\n",
    "#SBATCH --mail-type=END\n",
    "#SBATCH --mail-user=poldracklab@stanford.edu\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH -p russpold\n",
    "export PYTHONPATH=\"\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsl_command = '/share/software/user/open/fsl/5.0.10/bin/bet'\n",
    "sherlock_bids = '/oak/stanford/groups/russpold/data/uh2/aim1/BIDS_scans'\n",
    "sherlock_fsl = '/oak/stanford/groups/russpold/data/uh2/aim1/BIDS_scans/derivatives/fsl/inputs'\n",
    "fsl_flags = '  -f 0.5 -g 0 -m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "anats = glob(path.join(bids_dir, 'sub-*', 'ses-*', 'anat', '*_T1w*'))\n",
    "anats.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('../fsl/fsl_BET.batch', 'w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write(sbatch_headers)\n",
    "f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for anat in anats:\n",
    "    full_sub = anat.split('BIDS_scans/')[1].split('/ses')[0]\n",
    "    subid = full_sub.split('-')[1]\n",
    "\n",
    "    sesanat = anat.split(full_sub)[1]\n",
    "    sesanat = sesanat.strip('/')\n",
    "    \n",
    "    sesnums = re.findall(r'\\d', sesanat)\n",
    "    sesnum = sesnums[0]\n",
    "\n",
    "    t1_file = anat.split('/')[-1].replace('.nii.gz', '')\n",
    "\n",
    "    full_command = fsl_command+' '+path.join(sherlock_bids, full_sub, sesanat, t1_file)+' '+path.join(sherlock_fsl, subid, 'brain'+sesnum)+fsl_flags+'\\n'\n",
    "#     print(full_command)\n",
    "    f.write(full_command)\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P5 - building up bash scripts for each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_brain(task, subject, ses_num):\n",
    "    possible_brains = glob(path.join(fsl_input_path, subject, 'brain*_mask.nii.gz'))\n",
    "    if path.exists(path.join(fsl_input_path, subject, 'brain%s.nii.gz' % ses_num)): #if there is a brain for the session, use the appropiate brain\n",
    "        return path.join(fsl_input_path, subject, 'brain%s.nii.gz' % ses_num)\n",
    "    else: #use the default brain\n",
    "        return possible_brains[0].replace('_mask', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['ANT', 'CCTHot', 'DPX', 'WATT3', 'discountFix', 'motorSelectiveStop', 'stopSignal', 'stroop', 'twoByTwo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#build up bash scripts to run FEAT for different tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_headers='''fsl_dir=\"/home/groups/russpold/uh2_analysis/Self_Regulation_Ontology_fMRI/fmri_analysis/fsl\"\n",
    "template_dir=$fsl_dir/\"templates\"\n",
    "tmp_dir=$fsl_dir/\"tmp_batch\"\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANT\n",
      "check out the brain for s513\n",
      "check out the brain for s604\n",
      "CCTHot\n",
      "check out the brain for s513\n",
      "check out the brain for s604\n",
      "DPX\n",
      "check out the brain for s513\n",
      "check out the brain for s599\n",
      "check out the brain for s604\n",
      "WATT3\n",
      "check out the brain for s513\n",
      "check out the brain for s604\n",
      "discountFix\n",
      "check out the brain for s513\n",
      "check out the brain for s599\n",
      "check out the brain for s600\n",
      "check out the brain for s604\n",
      "motorSelectiveStop\n",
      "check out the brain for s513\n",
      "check out the brain for s599\n",
      "check out the brain for s600\n",
      "check out the brain for s604\n",
      "stopSignal\n",
      "check out the brain for s513\n",
      "check out the brain for s604\n",
      "stroop\n",
      "check out the brain for s513\n",
      "check out the brain for s599\n",
      "check out the brain for s604\n",
      "twoByTwo\n",
      "check out the brain for s513\n",
      "check out the brain for s604\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    print(task)\n",
    "    task_niftis = glob(path.join(bids_dir, 'sub-*', '*/func/*task-%s*_bold.nii.gz' % task))\n",
    "    task_niftis.sort()\n",
    "\n",
    "    loop_str = ''\n",
    "    for curr_nifti in task_niftis:\n",
    "        #break down path to get {RELATIVE_BOLD}, {SUBJECT}, {SES_BRAIN}, and {NTP}\n",
    "        relative_bold = curr_nifti.replace(bids_dir, '').replace('.nii.gz', '')\n",
    "        subject = relative_bold.replace('/sub-', '').split('/')[0]\n",
    "        ses_num = relative_bold.split('/ses-')[1].split('/')[0]\n",
    "        try:\n",
    "            BET_brain_path = get_relative_brain(task, subject, ses_num)\n",
    "            ses_brain = BET_brain_path.split('/')[-1].replace('.nii.gz', '')\n",
    "            img = nib.load(curr_nifti)\n",
    "            shape = img.header.get_data_shape()\n",
    "            ntp = shape[-1]\n",
    "            totV = np.prod(shape)\n",
    "\n",
    "            loop_str += ' %s,%s,%s,%s,%s' % (relative_bold, subject, ses_brain, ntp, totV) #THIS IS THE IMPORTANT BIT\n",
    "        except IndexError:\n",
    "            print('check out the brain for %s' % subject)\n",
    "\n",
    "    potential_str = \"OLDIFS=$IFS; IFS=',';\\nfor i in\"+loop_str+'; do set -- $i;\\n' +\"\"\"\\tsed -e \"s|{RELATIVE_BOLD}|$1|g\" -e \"s|{SUBJECT}|$2|g\" -e \"s|{SES_BRAIN}|$3|g\" -e \"s|{NTP}|$4|g\" -e \"s|{TOT_VOX}|$5|g\" $template_dir/template_%s_RT-True_fsl.fsf > $tmp_dir/%s_$2_RT-True_fsl.fsf;\n",
    "    sed -e \"s|{RELATIVE_BOLD}|$1|g\" -e \"s|{SUBJECT}|$2|g\" -e \"s|{SES_BRAIN}|$3|g\" -e \"s|{NTP}|$4|g\" -e \"s|{TOT_VOX}|$5|g\" $template_dir/template_%s_RT-False_fsl.fsf > $tmp_dir/%s_$2_RT-False_fsl.fsf;\n",
    "    sed -e \"s|{SUBJECT}|$2|g\" -e \"s|{TASK}|%s|g\" $template_dir/template_1stlevel_FEAT.batch > $tmp_dir/%s_$2_FEAT.batch;\n",
    "    sbatch $tmp_dir/%s_$2_FEAT.batch;\\ndone;\\nIFS=$OLDIFS;\n",
    "    \"\"\" % (task, task, task, task, task, task, task)\n",
    "    f=open('../fsl/run_%s_FEAT.sh' % task, 'w+')\n",
    "    f.write(sh_headers)\n",
    "    f.write('\\n')\n",
    "    f.write(potential_str)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
