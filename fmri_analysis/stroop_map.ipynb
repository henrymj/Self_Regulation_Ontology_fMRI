{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from os.path import abspath, join\n",
    "from nipype.interfaces import afni\n",
    "from nipype.interfaces.fsl import Level1Design, FEATModel, FILMGLS, FEAT, maths\n",
    "from nipype.algorithms.modelgen import SpecifyModel\n",
    "from nipype.interfaces.utility import Function, IdentityInterface\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.pipeline.engine import Workflow, Node\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Experiment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "experiment_dir = abspath('.')\n",
    "output_dir = 'datasink'\n",
    "working_dir = 'workingdir'\n",
    "\n",
    "# list of subject identifiers\n",
    "subject_list = ['sub-s358']\n",
    "\n",
    "# list of task identifiers\n",
    "task_list = ['stroop']\n",
    "\n",
    "# TR of functional images\n",
    "TR = .68\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###  Specify Contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Contrasts\n",
    "c1 = ['incongruent','T', ['incongruent'], [1]]\n",
    "c2 = ['congruent','T', ['congruent'], [1]]\n",
    "c3 = ['incongruent-congruent','T', ['incongruent','congruent'], [1,-1]]\n",
    "\n",
    "c4 = ['index','T', ['index_finger'], [1]]\n",
    "c5 = ['middle','T', ['middle_finger'], [1]]\n",
    "c6 = ['ring','T', ['ring_finger'], [1]]\n",
    "c7 = ['index vs others','T', ['index_finger','middle_finger', 'ring_finger'], [1,-.5,-.5]]\n",
    "\n",
    "contrast_list = [c1,c2,c3,c4,c5,c6,c7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Set up Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Specify GLM Model for Stroop Contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# helper function to create bunch\n",
    "def subjectinfo(subject_id, task, inspect_inputs=False):\n",
    "    \n",
    "    from glob import glob\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from os.path import join\n",
    "    from nipype.interfaces.base import Bunch\n",
    "    from utils.utils import parse_EVs\n",
    "    \n",
    "    base_dir = '/home/jovyan/work/output'\n",
    "    \n",
    "    # strip \"sub\" from beginning of subject_id if provided\n",
    "    subject_id = subject_id.replace('sub-','')\n",
    "    \n",
    "    ## Get the Events File\n",
    "    \n",
    "    # Read the TSV file and convert to pandas dataframe\n",
    "    event_file = glob(join(base_dir,\n",
    "                           'Data',\n",
    "                           'sub-%s' % subject_id,\n",
    "                           '*', 'func',\n",
    "                           '*%s*events.tsv' % task))[0]\n",
    "    events_df = pd.read_csv(event_file,sep = '\\t')\n",
    "\n",
    "    ## Get the Confounds File (output of fmriprep)\n",
    "    # Read the TSV file and convert to pandas dataframe\n",
    "    confounds_file = glob(join(base_dir,\n",
    "                               'Data',\n",
    "                               'sub-%s' % subject_id,\n",
    "                               '*', 'func',\n",
    "                               '*%s*confounds.tsv' % task))[0]\n",
    "    confounds_df = pd.read_csv(confounds_file, sep = '\\t', na_values=['n/a']).fillna(0)\n",
    "    # select relevant regressors\n",
    "    regressor_names = ['FramewiseDisplacement', \n",
    "                       'aCompCor0',\n",
    "                       'aCompCor1',\n",
    "                       'aCompCor2',\n",
    "                       'aCompCor3',\n",
    "                       'aCompCor4',\n",
    "                       'aCompCor5']\n",
    "    # convert selected regressors in dataframe to list of lists\n",
    "    regressors = confounds_df.loc[:,regressor_names].values.T.tolist()\n",
    "    \n",
    "    # set up contrasts\n",
    "    conditions, onsets, durations, amplitudes = parse_EVs(events_df,'stroop')\n",
    "    \n",
    "    subjectinfo = Bunch(conditions=conditions,\n",
    "                        onsets=onsets,\n",
    "                         durations=durations,\n",
    "                         amplitudes=amplitudes,\n",
    "                         tmod=None,\n",
    "                         pmod=None,\n",
    "                         regressor_names=regressor_names,\n",
    "                         regressors=regressors)\n",
    "    if inspect_inputs==True:\n",
    "        return events_df, confounds_df\n",
    "    else:\n",
    "        return subjectinfo  # this output will later be returned to infosource\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "View one events file used in subject info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>response_time</th>\n",
       "      <th>block_duration</th>\n",
       "      <th>correct</th>\n",
       "      <th>experiment_exp_id</th>\n",
       "      <th>key_press</th>\n",
       "      <th>stim_color</th>\n",
       "      <th>stim_word</th>\n",
       "      <th>timing_post_trial</th>\n",
       "      <th>trial_num</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>worker_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.510</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.807</td>\n",
       "      <td>2272.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>stroop</td>\n",
       "      <td>71</td>\n",
       "      <td>blue</td>\n",
       "      <td>red</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>incongruent</td>\n",
       "      <td>s358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.785</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.458</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>stroop</td>\n",
       "      <td>71</td>\n",
       "      <td>blue</td>\n",
       "      <td>red</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>incongruent</td>\n",
       "      <td>s358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.786</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.412</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>stroop</td>\n",
       "      <td>71</td>\n",
       "      <td>blue</td>\n",
       "      <td>blue</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>congruent</td>\n",
       "      <td>s358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.788</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.499</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>stroop</td>\n",
       "      <td>82</td>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>congruent</td>\n",
       "      <td>s358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.791</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.508</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>stroop</td>\n",
       "      <td>71</td>\n",
       "      <td>blue</td>\n",
       "      <td>green</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>incongruent</td>\n",
       "      <td>s358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    onset  duration  response_time  block_duration  correct experiment_exp_id  \\\n",
       "0   3.510       1.5          0.807          2272.0      1.0            stroop   \n",
       "1   5.785       1.5          0.458          2000.0      1.0            stroop   \n",
       "2   7.786       1.5          0.412          2000.0      1.0            stroop   \n",
       "3   9.788       1.5          0.499          2000.0      1.0            stroop   \n",
       "4  11.791       1.5          0.508          2000.0      1.0            stroop   \n",
       "\n",
       "   key_press stim_color stim_word  timing_post_trial  trial_num   trial_type  \\\n",
       "0         71       blue       red                0.0        0.0  incongruent   \n",
       "1         71       blue       red                0.0        1.0  incongruent   \n",
       "2         71       blue      blue                0.0        2.0    congruent   \n",
       "3         82      green     green                0.0        3.0    congruent   \n",
       "4         71       blue     green                0.0        4.0  incongruent   \n",
       "\n",
       "  worker_id  \n",
       "0      s358  \n",
       "1      s358  \n",
       "2      s358  \n",
       "3      s358  \n",
       "4      s358  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bunch = subjectinfo('s358','stroop')\n",
    "events_df,confounds_df = subjectinfo('s358','stroop',True)\n",
    "events_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Specify Input and Output Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get Subject Info - get subject specific condition information\n",
    "getsubjectinfo = Node(Function(input_names=['subject_id', 'task'],\n",
    "                               output_names=['subject_info'],\n",
    "                               function=subjectinfo),\n",
    "                      name='getsubjectinfo')\n",
    "\n",
    "# Infosource - a function free node to iterate over the list of subject names\n",
    "infosource = Node(IdentityInterface(fields=['subject_id',\n",
    "                                            'task',\n",
    "                                            'contrasts'],\n",
    "                                    contrasts=contrast_list),\n",
    "                  name=\"infosource\")\n",
    "infosource.iterables = [('subject_id', subject_list),\n",
    "                        ('task', task_list)]\n",
    "\n",
    "# SelectFiles - to grab the data (alternativ to DataGrabber)\n",
    "templates = {'func': join('Data', '{subject_id}','*','func',\n",
    "                         '*{task}*preproc.nii.gz'),\n",
    "            'mask': join('Data', '{subject_id}','*','func',\n",
    "                         '*{task}*brainmask.nii.gz')}\n",
    "selectfiles = Node(SelectFiles(templates,\n",
    "                               base_directory = experiment_dir,\n",
    "                               sort_filelist=True),\n",
    "                   name=\"selectfiles\")\n",
    "\n",
    "# Datasink - creates output folder for important outputs\n",
    "datasink = Node(DataSink(base_directory = experiment_dir,\n",
    "                         container=output_dir),\n",
    "                name=\"datasink\")\n",
    "\n",
    "# Use the following DataSink output substitutions\n",
    "substitutions = [('_subject_id_', ''),\n",
    "                ('fstat', 'FSTST'),\n",
    "                ('run0.mat', 'designfile.mat')]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# mask and blur\n",
    "masker = Node(maths.ApplyMask(),name='masker')\n",
    "\n",
    "# SpecifyModel - Generates FSL-specific Model\n",
    "modelspec = Node(SpecifyModel(input_units='secs',\n",
    "                              time_repetition=TR,\n",
    "                              high_pass_filter_cutoff=128),\n",
    "                 name=\"modelspec\")\n",
    "\n",
    "# Level1Design - Generates an FSL design matrix\n",
    "level1design = Node(Level1Design(bases={'dgamma':{'derivs': True}},\n",
    "                                 interscan_interval=TR,\n",
    "                                 model_serial_correlations=True),\n",
    "                    name=\"level1design\")\n",
    "\n",
    "# FEATmodel\n",
    "level1model = Node(FEATModel(), name=\"FEATModel\")\n",
    "\n",
    "# FILMGLs\n",
    "filmgls = Node(FILMGLS(autocorr_noestimate = True), name=\"FILMGLS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Run as separate nodes\n",
    "\n",
    "Useful for debugging"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "source": [
    "getsubjectinfo.inputs.subject_id = 'sub-s358' \n",
    "getsubjectinfo.inputs.task = 'stroop' \n",
    "subject_info = getsubjectinfo.run().outputs.subject_info\n",
    "\n",
    "selectfiles.inputs.subject_id = 'sub-s358' \n",
    "selectfiles.inputs.task = 'stroop' \n",
    "selectfiles_out = selectfiles.run()\n",
    "\n",
    "masker.inputs.in_file = selectfiles_out.outputs.func \n",
    "masker.inputs.mask_file = selectfiles_out.outputs.mask \n",
    "masker_out = masker.run()\n",
    "\n",
    "modelspec.inputs.subject_info = subject_info \n",
    "modelspec.inputs.functional_runs = masker_out.outputs.out_file \n",
    "modelspec_out = modelspec.run()\n",
    "\n",
    "level1design.inputs.contrasts = contrast_list\n",
    "level1design.inputs.session_info = modelspec_out.outputs.session_info \n",
    "level1design_out = level1design.run() \n",
    "level1design_out.outputs\n",
    "\n",
    "level1model.inputs.fsf_file = level1design_out.outputs.fsf_files \n",
    "level1model.inputs.ev_files = level1design_out.outputs.ev_files \n",
    "out=level1model.run()\n",
    "\n",
    "filmgls.inputs.in_file = masker_out.outputs.out_file \n",
    "filmgls.inputs.design_file = out.outputs.design_file \n",
    "filmgls.inputs.tcon_file = out.outputs.con_file \n",
    "filmgls.inputs.fcon_file = out.outputs.fcon_file \n",
    "fil_out = filmgls.run()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "desmtx=numpy.loadtxt(out.outputs.design_file,skiprows=5)\n",
    "plt.imshow(desmtx,aspect='auto',interpolation='nearest',cmap='gray')\n",
    "plt.title('Design Matrix')\n",
    "plt.show()\n",
    "cc=numpy.corrcoef(desmtx.T)\n",
    "plt.imshow(cc,aspect='auto',interpolation='nearest', cmap=plt.cm.viridis)\n",
    "plt.colorbar()\n",
    "plt.title('Correlation of Regressors')\n",
    "plt.show()\n",
    "# show first regressors\n",
    "plt.figure(figsize=[16,6])\n",
    "colors = ['m','c']\n",
    "for designi, conti in [(0,0),(2,1)]:\n",
    "    plt.plot(desmtx[:,designi], c=colors[conti], label=subject_info.conditions[conti])\n",
    "    ax = plt.gca()\n",
    "    for i in subject_info.onsets[conti]:\n",
    "        plt.axvline(i/.68, ymin=0, ymax=.1, c=colors[conti])\n",
    "plt.legend()\n",
    "plt.title('Incongruent Regressors')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import nilearn.plotting\n",
    "import nilearn.image\n",
    "\n",
    "nilearn.plotting.plot_glass_brain(nilearn.image.smooth_img(fil_out.outputs.zstats[0], 6),\n",
    "                                      display_mode='lyrz', colorbar=True, plot_abs=False, threshold=1)\n",
    "\n",
    "nilearn.plotting.plot_glass_brain(nilearn.image.smooth_img(fil_out.outputs.zstats[1], 6),\n",
    "                                      display_mode='lyrz', colorbar=True, plot_abs=False, threshold=1)\n",
    "\n",
    "nilearn.plotting.plot_glass_brain(nilearn.image.smooth_img(fil_out.outputs.zstats[2], 6),\n",
    "                                      display_mode='lyrz', colorbar=True, plot_abs=False, threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "\nTrying to connect l1analysis.getsubjectinfo:subject_info to l1analysis.datasink:1stLevel but input '1stLevel' of node 'l1analysis.datasink' is already\nconnected.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fb82969048fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                     (filmgls, datasink, [('zstats', '1stLevel.@Z'),\n\u001b[1;32m     25\u001b[0m                                         \u001b[0;34m(\u001b[0m\u001b[0;34m'fstats'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1stLevel.@F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                                         ('tstats','1stLevel.@T')])\n\u001b[0m\u001b[1;32m     27\u001b[0m                     ])\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/pipeline/engine/workflows.pyc\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0mTrying\u001b[0m \u001b[0mto\u001b[0m \u001b[0mconnect\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m \u001b[0mbut\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m'%s'\u001b[0m \u001b[0mof\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;34m'%s'\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0malready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0mconnected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m \"\"\" % (srcnode, source, destnode, dest, dest, destnode))\n\u001b[0m\u001b[1;32m    202\u001b[0m                 if not (hasattr(destnode, '_interface') and\n\u001b[1;32m    203\u001b[0m                             ('.io' in str(destnode._interface.__class__) or\n",
      "\u001b[0;31mException\u001b[0m: \nTrying to connect l1analysis.getsubjectinfo:subject_info to l1analysis.datasink:1stLevel but input '1stLevel' of node 'l1analysis.datasink' is already\nconnected.\n"
     ]
    }
   ],
   "source": [
    "# Initiation of the 1st-level analysis workflow\n",
    "l1analysis = Workflow(name='l1analysis')\n",
    "l1analysis.base_dir = join(experiment_dir, working_dir)\n",
    "\n",
    "# Connect up the 1st-level analysis components\n",
    "l1analysis.connect([(infosource, selectfiles, [('subject_id', 'subject_id'),\n",
    "                                               ('task', 'task')]),\n",
    "                    (infosource, getsubjectinfo, [('subject_id','subject_id'),\n",
    "                                                 ('task', 'task')]),\n",
    "                    (selectfiles, masker, [('func','in_file'),\n",
    "                                           ('mask', 'mask_file')]),\n",
    "                    (getsubjectinfo, modelspec, [('subject_info','subject_info')]),\n",
    "                    (masker, modelspec, [('out_file', 'functional_runs')]),\n",
    "                    (modelspec, level1design, [('session_info','session_info')]),\n",
    "                    (infosource, level1design, [('contrasts','contrasts')]),\n",
    "                    (level1design, level1model, [('ev_files', 'ev_files'),\n",
    "                                                 ('fsf_files','fsf_file')]),\n",
    "                    (masker, filmgls, [('out_file', 'in_file')]),\n",
    "                    (level1model, filmgls, [('design_file', 'design_file'),\n",
    "                                            ('con_file', 'tcon_file'),\n",
    "                                            ('fcon_file', 'fcon_file')]),\n",
    "                    (level1model, datasink, [('design_file', '1stLevel.design_file')]),\n",
    "                    (getsubjectinfo, datasink, [('subject_info', '1stLevel')]),\n",
    "                    (filmgls, datasink, [('zstats', '1stLevel.@Z'),\n",
    "                                        ('fstats', '1stLevel.@F'),\n",
    "                                        ('tstats','1stLevel.@T')])\n",
    "                    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Run the Workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170520-00:25:22,820 workflow INFO:\n",
      "\t Workflow l1analysis settings: ['check', 'execution', 'logging']\n",
      "170520-00:25:22,865 workflow INFO:\n",
      "\t Running in parallel.\n",
      "170520-00:25:22,876 workflow INFO:\n",
      "\t Executing: getsubjectinfo.a0 ID: 0\n",
      "170520-00:25:22,879 workflow INFO:\n",
      "\t [Job finished] jobname: getsubjectinfo.a0 jobid: 0\n",
      "170520-00:25:22,888 workflow INFO:\n",
      "\t Executing: selectfiles.a0 ID: 1\n",
      "170520-00:25:22,900 workflow INFO:\n",
      "\t Executing node selectfiles.a0 in dir: /home/jovyan/work/output/workingdir/l1analysis/_subject_id_sub-s358_task_stroop/selectfiles\n",
      "170520-00:25:22,967 workflow INFO:\n",
      "\t [Job finished] jobname: selectfiles.a0 jobid: 1\n",
      "170520-00:25:22,973 workflow INFO:\n",
      "\t Executing: masker.a0 ID: 2\n",
      "170520-00:25:22,988 workflow INFO:\n",
      "\t [Job finished] jobname: masker.a0 jobid: 2\n",
      "170520-00:25:22,993 workflow INFO:\n",
      "\t Executing: modelspec.a0 ID: 3\n",
      "170520-00:25:23,104 workflow INFO:\n",
      "\t [Job finished] jobname: modelspec.a0 jobid: 3\n",
      "170520-00:25:23,113 workflow INFO:\n",
      "\t Executing: level1design.a0 ID: 4\n",
      "170520-00:25:23,402 workflow INFO:\n",
      "\t [Job finished] jobname: level1design.a0 jobid: 4\n",
      "170520-00:25:23,410 workflow INFO:\n",
      "\t Executing: FEATModel.a0 ID: 5\n",
      "170520-00:25:23,546 workflow INFO:\n",
      "\t [Job finished] jobname: FEATModel.a0 jobid: 5\n",
      "170520-00:25:23,554 workflow INFO:\n",
      "\t Executing: FILMGLS.a0 ID: 6\n",
      "170520-00:25:23,586 workflow INFO:\n",
      "\t Executing node FILMGLS.a0 in dir: /home/jovyan/work/output/workingdir/l1analysis/_subject_id_sub-s358_task_stroop/FILMGLS\n",
      "170520-00:25:23,614 workflow INFO:\n",
      "\t Running: film_gls --noest --rn=results --con=/home/jovyan/work/output/workingdir/l1analysis/_subject_id_sub-s358_task_stroop/FEATModel/run0.con --in=/home/jovyan/work/output/workingdir/l1analysis/_subject_id_sub-s358_task_stroop/masker/sub-s358_ses-2_task-stroop_run-1_bold_space-MNI152NLin2009cAsym_preproc_masked.nii.gz --pd=/home/jovyan/work/output/workingdir/l1analysis/_subject_id_sub-s358_task_stroop/FEATModel/run0.mat --thr=0.000000\n",
      "170520-00:33:16,559 workflow INFO:\n",
      "\t [Job finished] jobname: FILMGLS.a0 jobid: 6\n",
      "170520-00:33:16,568 workflow INFO:\n",
      "\t Executing: datasink.a0 ID: 7\n",
      "170520-00:33:16,662 workflow INFO:\n",
      "\t Executing node datasink.a0 in dir: /home/jovyan/work/output/workingdir/l1analysis/_subject_id_sub-s358_task_stroop/datasink\n",
      "170520-00:33:16,925 interface INFO:\n",
      "\t sub: /home/jovyan/work/output/datasink/1stLevel/_subject_id_sub-s358_task_stroop/tstat1.nii.gz -> /home/jovyan/work/output/datasink/1stLevel/sub-s358_task_stroop/tstat1.nii.gz\n",
      "170520-00:33:16,934 interface INFO:\n",
      "\t sub: /home/jovyan/work/output/datasink/1stLevel/_subject_id_sub-s358_task_stroop/tstat2.nii.gz -> /home/jovyan/work/output/datasink/1stLevel/sub-s358_task_stroop/tstat2.nii.gz\n",
      "170520-00:33:16,940 interface INFO:\n",
      "\t sub: /home/jovyan/work/output/datasink/1stLevel/_subject_id_sub-s358_task_stroop/tstat3.nii.gz -> /home/jovyan/work/output/datasink/1stLevel/sub-s358_task_stroop/tstat3.nii.gz\n",
      "170520-00:33:16,941 interface INFO:\n",
      "\t sub: /home/jovyan/work/output/datasink/1stLevel/_subject_id_sub-s358_task_stroop/tstat4.nii.gz -> /home/jovyan/work/output/datasink/1stLevel/sub-s358_task_stroop/tstat4.nii.gz\n",
      "170520-00:33:16,943 interface INFO:\n",
      "\t sub: /home/jovyan/work/output/datasink/1stLevel/_subject_id_sub-s358_task_stroop/tstat5.nii.gz -> /home/jovyan/work/output/datasink/1stLevel/sub-s358_task_stroop/tstat5.nii.gz\n",
      "170520-00:33:16,953 interface INFO:\n",
      "\t sub: /home/jovyan/work/output/datasink/1stLevel/_subject_id_sub-s358_task_stroop/tstat6.nii.gz -> /home/jovyan/work/output/datasink/1stLevel/sub-s358_task_stroop/tstat6.nii.gz\n",
      "170520-00:33:16,956 interface INFO:\n",
      "\t sub: /home/jovyan/work/output/datasink/1stLevel/_subject_id_sub-s358_task_stroop/tstat7.nii.gz -> /home/jovyan/work/output/datasink/1stLevel/sub-s358_task_stroop/tstat7.nii.gz\n",
      "170520-00:33:17,72 workflow ERROR:\n",
      "\t [u'Node datasink.a0 failed to run on host f2c8a4b8bc00.']\n",
      "170520-00:33:17,73 workflow INFO:\n",
      "\t Saving crash info to /home/jovyan/work/output/crash-20170520-003317-jovyan-datasink.a0-eeed0caf-650b-4c5a-9e5c-9e4535998910.pklz\n",
      "170520-00:33:17,74 workflow INFO:\n",
      "\t Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/pipeline/plugins/multiproc.py\", line 52, in run_node\n",
      "    result['result'] = node.run(updatehash=updatehash)\n",
      "  File \"/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/pipeline/engine/nodes.py\", line 366, in run\n",
      "    self._run_interface()\n",
      "  File \"/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/pipeline/engine/nodes.py\", line 476, in _run_interface\n",
      "    self._result = self._run_command(execute)\n",
      "  File \"/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/pipeline/engine/nodes.py\", line 607, in _run_command\n",
      "    result = self._interface.run()\n",
      "  File \"/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/interfaces/base.py\", line 1086, in run\n",
      "    outputs = self.aggregate_outputs(runtime)\n",
      "  File \"/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/interfaces/base.py\", line 1157, in aggregate_outputs\n",
      "    predicted_outputs = self._list_outputs()\n",
      "  File \"/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/interfaces/io.py\", line 717, in _list_outputs\n",
      "    for src in filename_to_list(files):\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "Interface DataSink failed to run. \n",
      "\n",
      "170520-00:33:17,224 workflow INFO:\n",
      "\t ***********************************\n",
      "170520-00:33:17,226 workflow ERROR:\n",
      "\t could not run node: l1analysis.datasink.a0\n",
      "170520-00:33:17,228 workflow INFO:\n",
      "\t crashfile: /home/jovyan/work/output/crash-20170520-003317-jovyan-datasink.a0-eeed0caf-650b-4c5a-9e5c-9e4535998910.pklz\n",
      "170520-00:33:17,230 workflow INFO:\n",
      "\t ***********************************\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Workflow did not execute cleanly. Check log for details",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5eb76c2ecef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml1analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MultiProc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'n_procs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/pipeline/engine/workflows.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_report'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0mdatestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%dT%H%M%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'write_provenance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/pipeline/plugins/base.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_node_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mreport_nodes_not_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# close any open resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/pipeline/plugins/base.pyc\u001b[0m in \u001b[0;36mreport_nodes_not_run\u001b[0;34m(notrun)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***********************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise RuntimeError(('Workflow did not execute cleanly. '\n\u001b[0m\u001b[1;32m     96\u001b[0m                             'Check log for details'))\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Workflow did not execute cleanly. Check log for details"
     ]
    }
   ],
   "source": [
    "l1analysis.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualize Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create 1st-level analysis output graph\n",
    "l1analysis.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "\n",
    "# Visualize the graph\n",
    "from IPython.display import Image\n",
    "Image(filename=join(l1analysis.base_dir, 'l1analysis', 'graph.dot.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualize Design Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!tree datasink/1stLevel/sub*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "design_file = glob(join(experiment_dir,'datasink','1stLevel','sub-s358_task_stroop','designfile.mat'))[0]\n",
    "desmtx=numpy.loadtxt(design_file, skiprows=5)\n",
    "plt.imshow(desmtx,aspect='auto',interpolation='nearest',cmap='gray')\n",
    "plt.title('Design Matrix')\n",
    "plt.show()\n",
    "cc=numpy.corrcoef(desmtx.T)\n",
    "plt.imshow(cc,aspect='auto',interpolation='nearest', cmap=plt.cm.viridis)\n",
    "plt.colorbar()\n",
    "plt.title('Correlation of Regressors')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "# show first regressors\n",
    "plt.figure(figsize=[20,8])\n",
    "plt.plot(desmtx[:,0],'b', label=subject_info.conditions[0])\n",
    "plt.plot(desmtx[:,2],'r', label=subject_info.conditions[1])\n",
    "for i in subject_info.onsets[0]:\n",
    "    plt.axvline(i/.68, ymin=0, ymax=.1)\n",
    "for i in subject_info.onsets[1]:\n",
    "    plt.axvline(i/.68, ymin=0, ymax=.1, c='r')\n",
    "plt.legend()\n",
    "plt.title('Congruent/Incongruent Regressors')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map\n",
    "anatimg = glob(join(experiment_dir,'Data','sub-s358','anat','*T1w*MNI*preproc*'))[0]\n",
    "contrast_img = glob(join(experiment_dir,'datasink','1stLevel','sub-s358_task_stroop','zstat1.nii.gz'))[0]\n",
    "plot_stat_map(contrast_img, title='stroop effect',\n",
    "              bg_img=anatimg, threshold=2.3, display_mode='z', cut_coords=(-30, -15, 0, 15, 30), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nilearn.plotting\n",
    "import nilearn.image\n",
    "contrast_img = glob(join(experiment_dir,'datasink','1stLevel','sub-s358_task_stroop','zstat1.nii.gz'))[0]\n",
    "nilearn.plotting.plot_glass_brain(nilearn.image.smooth_img(contrast_img, 8),\n",
    "                                      display_mode='lyrz', colorbar=True, plot_abs=False, threshold=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
